{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Assignment 2**","metadata":{}},{"cell_type":"markdown","source":"# TASK 1 \n1. Fill missing values using generative model (Autoencoder)\n2. Measure the perfomence of autoencoder approach perfomence and compare with statistical approaches (i.e From here)\n3. Reduce the dimenssion of the data using Principal component analysis and Linear Discriminant Analysis and compare the impact on selected machine learning model","metadata":{}},{"cell_type":"code","source":"!pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:03.760964Z","iopub.execute_input":"2022-05-18T05:35:03.761280Z","iopub.status.idle":"2022-05-18T05:35:13.935106Z","shell.execute_reply.started":"2022-05-18T05:35:03.761231Z","shell.execute_reply":"2022-05-18T05:35:13.934118Z"},"trusted":true},"execution_count":241,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchsummary import summary\nfrom torch.utils.data import TensorDataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:13.937920Z","iopub.execute_input":"2022-05-18T05:35:13.938399Z","iopub.status.idle":"2022-05-18T05:35:13.952234Z","shell.execute_reply.started":"2022-05-18T05:35:13.938359Z","shell.execute_reply":"2022-05-18T05:35:13.951490Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"identity = pd.read_csv('../input/assignment2data/data_identity.csv', encoding = 'utf-8')\ntransaction = pd.read_csv('../input/assignment2data/data_transaction.csv', encoding = 'utf-8')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:13.953703Z","iopub.execute_input":"2022-05-18T05:35:13.954320Z","iopub.status.idle":"2022-05-18T05:35:49.780705Z","shell.execute_reply.started":"2022-05-18T05:35:13.954275Z","shell.execute_reply":"2022-05-18T05:35:49.779972Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"cat_feats_transaction = transaction.select_dtypes(include=['object']).columns.tolist()\ncat_feats_identity = identity.select_dtypes(include=['object']).columns.tolist()\ntransaction = transaction.drop(columns = cat_feats_transaction)\nidentity = identity.drop(columns = cat_feats_identity)\ndf = pd.merge(transaction, identity , on = 'TransactionID')\ndf_label = df['isFraud']\ndf = df.drop(columns = ['isFraud'])\n\ndf.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:49.782953Z","iopub.execute_input":"2022-05-18T05:35:49.783215Z","iopub.status.idle":"2022-05-18T05:35:52.165558Z","shell.execute_reply.started":"2022-05-18T05:35:49.783180Z","shell.execute_reply":"2022-05-18T05:35:52.154655Z"},"trusted":true},"execution_count":244,"outputs":[{"execution_count":244,"output_type":"execute_result","data":{"text/plain":"(144233, 402)"},"metadata":{}}]},{"cell_type":"code","source":"identity = None\ntransaction = None","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:52.166731Z","iopub.execute_input":"2022-05-18T05:35:52.167003Z","iopub.status.idle":"2022-05-18T05:35:52.186708Z","shell.execute_reply.started":"2022-05-18T05:35:52.166969Z","shell.execute_reply":"2022-05-18T05:35:52.185890Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"# from sklearn import preprocessing\n# encoder = preprocessing.LabelEncoder()\n# for feature in cat_feats_transaction:\n#     transaction[feature] = encoder.fit_transform(transaction[feature])\n# for feature in cat_feats_identity:\n#     identity[feature] = encoder.fit_transform(identity[feature])\n\n\n# import numpy as np\n# from sklearn.impute import SimpleImputer\n# imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n# imputer.fit_transform(df)\n\n\n\n\n# from sklearn.preprocessing import MinMaxScaler\n# scaler = MinMaxScaler()\n# scaler.fit_transform(df)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:52.192290Z","iopub.execute_input":"2022-05-18T05:35:52.194941Z","iopub.status.idle":"2022-05-18T05:35:52.210002Z","shell.execute_reply.started":"2022-05-18T05:35:52.194245Z","shell.execute_reply":"2022-05-18T05:35:52.209062Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"markdown","source":"# Simple autoencoder","metadata":{}},{"cell_type":"code","source":"## SIMPLE AUTOENCODER\nclass autoencoder(nn.Module):\n    def __init__(self, input_size, latent_dim = 10):\n      super(autoencoder, self).__init__()\n      self.encoder = nn.Sequential(\n          nn.Linear(input_size, input_size//2),\n          nn.ReLU(),\n          nn.Linear(input_size//2, input_size//4),\n          nn.ReLU(),\n          nn.Linear(input_size//4, input_size//8),\n          nn.ReLU(),\n          nn.Linear(input_size//8, latent_dim)\n      )\n      self.decoder = nn.Sequential(\n          nn.Linear(latent_dim, input_size//8),\n          nn.ReLU(),\n          nn.Linear(input_size//8, input_size//4),\n          nn.ReLU(),\n          nn.Linear(input_size//4, input_size//2)\n      )\n      self.encoder.apply(self.__init_weights)\n      self.decoder.apply(self.__init_weights)\n        \n    def forward(self, x):\n      x = self.encoder(x)\n      x = self.decoder(x)\n      return x\n    \n    def __init_weights(self,m):\n      if type(m) == nn.Linear:\n          torch.nn.init.xavier_uniform_(m.weight)\n          m.bias.data.fill_(0.01)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:52.211909Z","iopub.execute_input":"2022-05-18T05:35:52.214447Z","iopub.status.idle":"2022-05-18T05:35:52.250001Z","shell.execute_reply.started":"2022-05-18T05:35:52.214392Z","shell.execute_reply":"2022-05-18T05:35:52.249184Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"def train(model, data, batch_size, regularized = False, lr = 1e-6, loss = nn.MSELoss(), train_epochs = 100):\n    data = torch.tensor(data)\n    n_features = data.shape[1]\n    model = model(n_features * 2).to(device)\n    indicator = torch.isnan(data)\n    data[indicator] = 1\n    data_with_indicator = torch.hstack([data, ~indicator])\n    X_train, X_test = train_test_split(data_with_indicator, test_size = 0.2, random_state = 42)\n    train_data_loader = torch.utils.data.DataLoader(X_train.to(device), batch_size = batch_size,\n                                                             shuffle = True)\n    print(len(train_data_loader))\n    test_data_loader = torch.utils.data.DataLoader(X_test.to(device), batch_size = batch_size,\n                                                            shuffle = False)\n    \n    if regularized:\n        criterion = nn.L1Loss()\n    else:\n        criterion = nn.MSELoss()\n \n    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n    history = {'train_loss': [], 'test_loss': []}\n    print(model)\n    def _train_epoch(model, optimizer, criterion):\n        epoch_loss = 0\n        model.train()\n\n        for batch in train_data_loader:\n            batch_input = batch.to(device)\n            optimizer.zero_grad()\n            pred = model(batch_input)\n            if not regularized:\n                input_values = batch_input[:, :n_features]\n                missing_indicator = batch_input[:, n_features:]\n                loss = criterion(input_values * (1 - missing_indicator), pred * (1 - missing_indicator))\n                loss1 = loss\n            else:\n                input_values = batch_input[:, :n_features]\n                missing_indicator = batch_input[:, n_features:]\n                observed_indicator = 1 - missing_indicator\n                criterion_loss = criterion(input_values * (1 - missing_indicator), pred * (1 - missing_indicator))\n                loss = 0\n                model_children = list(model.children())\n                values = batch_input\n                for i in range(len(model_children)):\n                    values = F.relu((model_children[i](values)))\n                    loss += torch.mean(torch.abs(values))\n                loss = 0.5 * loss + criterion_loss\n                loss1 = criterion_loss\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss1.item()\n\n        return epoch_loss / len(train_data_loader)\n    \n    def test_epoch(model, criterion):\n        model.eval()\n        with torch.no_grad():\n            pred = model(test_data_loader.dataset)\n            input_test = test_data_loader.dataset\n            input_values = input_test[:, :n_features]\n            missing_indicator = input_test[:, n_features:]\n            observed_indicator = 1 - missing_indicator\n            loss = criterion(input_values * (1 - missing_indicator), pred * (1 - missing_indicator))\n        return loss.item()\n    \n    for epoch in range(train_epochs):\n        train_loss = _train_epoch(model, optimizer, criterion)\n        test_loss = test_epoch(model, criterion)\n        history['train_loss'].append(train_loss)\n        history['test_loss'].append(test_loss)\n        if epoch % 10 == 0:\n            print('epoch', epoch, \"train_loss:\", train_loss, 'test_loss:', test_loss)\n    best = np.argmin(history['test_loss'])\n    ae_performance = [history['train_loss'][best], history['test_loss'][best]]\n    return ae_performance, model\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:52.256278Z","iopub.execute_input":"2022-05-18T05:35:52.258652Z","iopub.status.idle":"2022-05-18T05:35:52.337985Z","shell.execute_reply.started":"2022-05-18T05:35:52.258592Z","shell.execute_reply":"2022-05-18T05:35:52.337132Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"\n\nclass VAE(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, input_size // 4), \n            nn.ReLU(),\n            nn.BatchNorm1d(input_size // 4, momentum = 0.7),\n            nn.Linear(input_size // 4, input_size // 16), \n            nn.ReLU(),\n            nn.BatchNorm1d(input_size // 16, momentum = 0.7),\n            nn.Linear(input_size // 16, input_size // 32), \n            nn.LeakyReLU()\n        )\n        self.hidden2mu = nn.Linear(input_size // 32, input_size // 32)\n        self.hidden2log_var = nn.Linear(input_size // 32, input_size // 32)\n\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(input_size // 32, input_size // 16), \n            nn.ReLU(),\n            nn.Linear(input_size // 16, input_size // 8), \n            nn.ReLU(),\n            nn.Linear(input_size // 8, int(input_size / 2)), \n            nn.ReLU()\n        )\n\n    def encode(self, x):\n        hidden = self.encoder(x)\n        mu = self.hidden2mu(hidden)\n        log_var = self.hidden2log_var(hidden)\n        return mu, log_var\n\n    def reparametrize(self, mu, log_var):\n        sigma = torch.exp(log_var/2)\n        z = torch.randn(size=(mu.size(0), mu.size(1)))\n        z = z.type_as(mu)\n        return mu + sigma * z\n\n    def forward(self, x):\n        mu, log_var = self.encode(x)\n        hidden = self.reparametrize(mu, log_var)\n        return self.decoder(hidden)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:52.342496Z","iopub.execute_input":"2022-05-18T05:35:52.345614Z","iopub.status.idle":"2022-05-18T05:35:52.390875Z","shell.execute_reply.started":"2022-05-18T05:35:52.345571Z","shell.execute_reply":"2022-05-18T05:35:52.389873Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"\ndef train2(model, data, batch_size, lr = 1e-6, loss = nn.MSELoss(), train_epochs = 100):\n    data = torch.tensor(data)\n    n_features = data.shape[1]\n    model = model(n_features * 2).to(device)\n    indicator = torch.isnan(data)\n    data[indicator] = 1\n    data_with_indicator = torch.hstack([data, ~indicator])\n    X_train, X_test = train_test_split(data_with_indicator, test_size = 0.2, random_state = 42)\n    train_data_loader = torch.utils.data.DataLoader(X_train.to(device), batch_size = batch_size,\n                                                             shuffle = True)\n    test_data_loader = torch.utils.data.DataLoader(X_test.to(device), batch_size = batch_size,\n                                                            shuffle = False)\n    criterion = nn.MSELoss()\n    \n \n    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n    history = {'train_loss': [], 'test_loss': []}\n    print(model)\n \n    def _train_epoch(model, optimizer, criterion):\n        epoch_loss = 0\n        model.train()\n\n        for batch in train_data_loader:\n            batch_input = batch.to(device)\n            optimizer.zero_grad()\n            mu, log_var = model.encode(batch_input)\n            pred = model(batch_input)\n            kl_loss = (-0.5 * (1 + log_var - mu ** 2 - torch.exp(log_var)).sum(dim=1)).mean(dim=0)\n            input_values = batch_input[:, :n_features]\n            missing_indicator = batch_input[:, n_features:]\n            loss = criterion(input_values * (1 - missing_indicator), pred * (1 - missing_indicator)) + kl_loss\n            loss1 = criterion(input_values * (1 - missing_indicator), pred * (1 - missing_indicator))\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss1.item()\n\n        return epoch_loss / len(train_data_loader)\n\n    def test_epoch( model, criterion):\n        model.eval()\n        with torch.no_grad():\n            pred = model(test_data_loader.dataset)\n#             nans = pred.isnan()\n#             pred[nans] = 0\n            input_test = test_data_loader.dataset\n            input_values = input_test[:, :n_features]\n            missing_indicator = input_test[:, n_features:]\n            loss = criterion(input_values * (1 - missing_indicator), pred * (1 - missing_indicator))\n        return loss.item()\n    \n    for epoch in range(train_epochs):\n        train_loss = _train_epoch(model, optimizer, criterion)\n        test_loss = test_epoch(model, criterion)\n        history['train_loss'].append(train_loss)\n        history['test_loss'].append(test_loss)\n        if epoch % 10 == 0:\n            print('epoch', epoch, \"train_loss:\", train_loss, 'test_loss:', test_loss)\n    best = np.argmin(history['test_loss'])\n    ae_performance = [history['train_loss'][best], history['test_loss'][best]]\n    return ae_performance, model\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:52.403352Z","iopub.execute_input":"2022-05-18T05:35:52.407127Z","iopub.status.idle":"2022-05-18T05:35:52.444125Z","shell.execute_reply.started":"2022-05-18T05:35:52.407052Z","shell.execute_reply":"2022-05-18T05:35:52.443292Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"x = torch.torch.from_numpy(df.values).to(torch.float32)\nmodel_simple = autoencoder\nmodel_reg = autoencoder\nmodel_vae = VAE\n\nae, ae_model = train(model_simple, x, batch_size=512, train_epochs = 120 , lr=1e-6)\nae_reg, ae_reg_model = train(model_reg, x, batch_size=512, regularized = True, train_epochs = 100 , lr=1e-6)\nvae, vae_model = train2(model_vae, x, batch_size=512, train_epochs = 100 , lr=1e-6)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:35:52.449637Z","iopub.execute_input":"2022-05-18T05:35:52.452014Z","iopub.status.idle":"2022-05-18T05:43:07.460530Z","shell.execute_reply.started":"2022-05-18T05:35:52.451970Z","shell.execute_reply":"2022-05-18T05:43:07.459660Z"},"trusted":true},"execution_count":251,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"},{"name":"stdout","text":"226\nautoencoder(\n  (encoder): Sequential(\n    (0): Linear(in_features=804, out_features=402, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=402, out_features=201, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=201, out_features=100, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=100, out_features=10, bias=True)\n  )\n  (decoder): Sequential(\n    (0): Linear(in_features=10, out_features=100, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=100, out_features=201, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=201, out_features=402, bias=True)\n  )\n)\nepoch 0 train_loss: 124315000.74336283 test_loss: 90467080.0\nepoch 10 train_loss: 591619.6942754425 test_loss: 494031.59375\nepoch 20 train_loss: 89310.05548257743 test_loss: 85393.0546875\nepoch 30 train_loss: 31682.121465362277 test_loss: 31054.728515625\nepoch 40 train_loss: 12148.818398264657 test_loss: 11914.4296875\nepoch 50 train_loss: 4867.962590310426 test_loss: 4763.90185546875\nepoch 60 train_loss: 1942.1551481263828 test_loss: 1894.2249755859375\nepoch 70 train_loss: 820.0211308572144 test_loss: 806.6248779296875\nepoch 80 train_loss: 399.78766220227806 test_loss: 395.86968994140625\nepoch 90 train_loss: 217.00812976128233 test_loss: 217.38082885742188\nepoch 100 train_loss: 128.3470718923923 test_loss: 128.3999481201172\nepoch 110 train_loss: 78.53314897655386 test_loss: 79.84587860107422\n226\nautoencoder(\n  (encoder): Sequential(\n    (0): Linear(in_features=804, out_features=402, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=402, out_features=201, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=201, out_features=100, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=100, out_features=10, bias=True)\n  )\n  (decoder): Sequential(\n    (0): Linear(in_features=10, out_features=100, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=100, out_features=201, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=201, out_features=402, bias=True)\n  )\n)\nepoch 0 train_loss: 4365.684357499655 test_loss: 3918.737060546875\nepoch 10 train_loss: 1273.218822918107 test_loss: 1188.535888671875\nepoch 20 train_loss: 201.3265567880816 test_loss: 181.98741149902344\nepoch 30 train_loss: 63.6534491007307 test_loss: 60.27947235107422\nepoch 40 train_loss: 29.30002936641727 test_loss: 28.312673568725586\nepoch 50 train_loss: 16.660649248984008 test_loss: 16.270479202270508\nepoch 60 train_loss: 10.573334271928905 test_loss: 10.376480102539062\nepoch 70 train_loss: 7.224589628455913 test_loss: 7.101523399353027\nepoch 80 train_loss: 5.113213406199902 test_loss: 5.0554728507995605\nepoch 90 train_loss: 3.7231873083958584 test_loss: 3.6989924907684326\nVAE(\n  (encoder): Sequential(\n    (0): Linear(in_features=804, out_features=201, bias=True)\n    (1): ReLU()\n    (2): BatchNorm1d(201, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n    (3): Linear(in_features=201, out_features=50, bias=True)\n    (4): ReLU()\n    (5): BatchNorm1d(50, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n    (6): Linear(in_features=50, out_features=25, bias=True)\n    (7): LeakyReLU(negative_slope=0.01)\n  )\n  (hidden2mu): Linear(in_features=25, out_features=25, bias=True)\n  (hidden2log_var): Linear(in_features=25, out_features=25, bias=True)\n  (decoder): Sequential(\n    (0): Linear(in_features=25, out_features=50, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=50, out_features=100, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=100, out_features=402, bias=True)\n    (5): ReLU()\n  )\n)\nepoch 0 train_loss: 0.2322823535156461 test_loss: 127748450287616.0\nepoch 10 train_loss: 0.22310503288707903 test_loss: 0.2227020412683487\nepoch 20 train_loss: 0.20925186640393417 test_loss: 0.20843742787837982\nepoch 30 train_loss: 0.1908135544014188 test_loss: inf\nepoch 40 train_loss: 0.16763881580755774 test_loss: inf\nepoch 50 train_loss: 0.14103435335961062 test_loss: inf\nepoch 60 train_loss: 0.11260132498182027 test_loss: inf\nepoch 70 train_loss: 0.08478578602054478 test_loss: inf\nepoch 80 train_loss: 0.0601971577193621 test_loss: 11127.9453125\nepoch 90 train_loss: 0.04100886735636576 test_loss: 0.04027553275227547\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nX = ['train_loss','test_loss']\nX_axis = np.arange(len(X))\n  \nplt.bar(X_axis + 0.2, ae, 0.1, label = 'simple')\nplt.bar(X_axis, ae_reg, 0.1, label = 'regularized')\nplt.bar(X_axis - 0.2, vae, 0.1, label = 'vae')\n\n\nplt.xticks(X_axis, X)\nplt.ylabel(\"MSE\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:43:07.462635Z","iopub.execute_input":"2022-05-18T05:43:07.463030Z","iopub.status.idle":"2022-05-18T05:43:07.741975Z","shell.execute_reply.started":"2022-05-18T05:43:07.462960Z","shell.execute_reply":"2022-05-18T05:43:07.741163Z"},"trusted":true},"execution_count":252,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"x = torch.torch.from_numpy(df.values).to(torch.float32)\ndata = torch.tensor(x)\nindicator = torch.isnan(data)\ndata[indicator] = 1\ndata_with_indicator = torch.hstack([data, ~indicator])\ndata_loader = torch.utils.data.DataLoader(data_with_indicator.to(device), batch_size = 128,\n                                                             shuffle = False)\nae_model.eval()\nwith torch.no_grad():\n    pred = ae_model(data_loader.dataset)\n    nans = pred.isnan()\n    pred[nans] = 0\n\npred.shape\nX1 = pred.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:23.718595Z","iopub.execute_input":"2022-05-18T05:44:23.718895Z","iopub.status.idle":"2022-05-18T05:44:25.881945Z","shell.execute_reply.started":"2022-05-18T05:44:23.718862Z","shell.execute_reply":"2022-05-18T05:44:25.881118Z"},"trusted":true},"execution_count":255,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"X1.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:34.333239Z","iopub.execute_input":"2022-05-18T05:44:34.333560Z","iopub.status.idle":"2022-05-18T05:44:34.339841Z","shell.execute_reply.started":"2022-05-18T05:44:34.333527Z","shell.execute_reply":"2022-05-18T05:44:34.339022Z"},"trusted":true},"execution_count":257,"outputs":[{"execution_count":257,"output_type":"execute_result","data":{"text/plain":"(144233, 402)"},"metadata":{}}]},{"cell_type":"code","source":"x = torch.torch.from_numpy(df.values).to(torch.float32)\ndata = torch.tensor(x)\nindicator = torch.isnan(data)\ndata[indicator] = 1\ndata_with_indicator = torch.hstack([data, ~indicator])\ndata_loader = torch.utils.data.DataLoader(data_with_indicator.to(device), batch_size = 128,\n                                                             shuffle = False)\nae_reg_model.eval()\nwith torch.no_grad():\n    pred = ae_reg_model(data_loader.dataset)\n    nans = pred.isnan()\n    pred[nans] = 0\n\npred.shape\nX2 = pred.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:39.070374Z","iopub.execute_input":"2022-05-18T05:44:39.070896Z","iopub.status.idle":"2022-05-18T05:44:41.174115Z","shell.execute_reply.started":"2022-05-18T05:44:39.070843Z","shell.execute_reply":"2022-05-18T05:44:41.173068Z"},"trusted":true},"execution_count":258,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"x = torch.torch.from_numpy(df.values).to(torch.float32)\ndata = torch.tensor(x)\nindicator = torch.isnan(data)\ndata[indicator] = 1\ndata_with_indicator = torch.hstack([data, ~indicator])\ndata_loader = torch.utils.data.DataLoader(data_with_indicator.to(device), batch_size = 128,\n                                                             shuffle = False)\nvae_model.eval()\nwith torch.no_grad():\n    pred = vae_model(data_loader.dataset)\n    nans = pred.isnan()\n    pred[nans] = 0\n\npred.shape\nX3 = pred.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:43.071541Z","iopub.execute_input":"2022-05-18T05:44:43.072050Z","iopub.status.idle":"2022-05-18T05:44:45.170420Z","shell.execute_reply.started":"2022-05-18T05:44:43.072014Z","shell.execute_reply":"2022-05-18T05:44:45.169681Z"},"trusted":true},"execution_count":259,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"y = df_label\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:46.539944Z","iopub.execute_input":"2022-05-18T05:44:46.540201Z","iopub.status.idle":"2022-05-18T05:44:46.545478Z","shell.execute_reply.started":"2022-05-18T05:44:46.540172Z","shell.execute_reply":"2022-05-18T05:44:46.544710Z"},"trusted":true},"execution_count":260,"outputs":[{"execution_count":260,"output_type":"execute_result","data":{"text/plain":"(144233,)"},"metadata":{}}]},{"cell_type":"code","source":"X1.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:48.901911Z","iopub.execute_input":"2022-05-18T05:44:48.902204Z","iopub.status.idle":"2022-05-18T05:44:48.911713Z","shell.execute_reply.started":"2022-05-18T05:44:48.902172Z","shell.execute_reply":"2022-05-18T05:44:48.910630Z"},"trusted":true},"execution_count":261,"outputs":[{"execution_count":261,"output_type":"execute_result","data":{"text/plain":"(144233, 402)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nclf = PassiveAggressiveClassifier()\n\n\nX1_train, X1_test, y_train, y_test = train_test_split(\n    X1, y, test_size = 0.2, random_state = 0)\n\n\nclf.fit(X1_train, y_train)\nprint(classification_report(clf.predict(X1_test), y_test, digits = 6))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:52.844027Z","iopub.execute_input":"2022-05-18T05:44:52.844330Z","iopub.status.idle":"2022-05-18T05:44:54.462655Z","shell.execute_reply.started":"2022-05-18T05:44:52.844289Z","shell.execute_reply":"2022-05-18T05:44:54.460107Z"},"trusted":true},"execution_count":262,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0   0.998497  0.922511  0.959001     28804\n           1   0.001342  0.069767  0.002634        43\n\n    accuracy                       0.921240     28847\n   macro avg   0.499920  0.496139  0.480817     28847\nweighted avg   0.997011  0.921240  0.957575     28847\n\n","output_type":"stream"}]},{"cell_type":"code","source":"X2_train, X2_test, y_train, y_test = train_test_split(\n    X2, y, test_size = 0.2, random_state = 0)\n\nclf.fit(X2_train, y_train)\nprint (classification_report(clf.predict(X2_test),y_test, digits = 6))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:44:55.793166Z","iopub.execute_input":"2022-05-18T05:44:55.794077Z","iopub.status.idle":"2022-05-18T05:44:57.532095Z","shell.execute_reply.started":"2022-05-18T05:44:55.794027Z","shell.execute_reply":"2022-05-18T05:44:57.529441Z"},"trusted":true},"execution_count":263,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0   0.999399  0.922543  0.959434     28829\n           1   0.000895  0.111111  0.001775        18\n\n    accuracy                       0.922037     28847\n   macro avg   0.500147  0.516827  0.480605     28847\nweighted avg   0.998776  0.922037  0.958837     28847\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan, strategy='mean')\nimputer.fit(df)\nimputed_df = imputer.transform(df)\nX_imp_train, X_imp_test, y_train, y_test = train_test_split(\n    X2, y, test_size = 0.2, random_state = 0)\n\nclf.fit(X_imp_train, y_train)\nprint (classification_report(clf.predict(X_imp_test),y_test, digits = 6))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:45:00.061617Z","iopub.execute_input":"2022-05-18T05:45:00.061865Z","iopub.status.idle":"2022-05-18T05:45:04.295072Z","shell.execute_reply.started":"2022-05-18T05:45:00.061837Z","shell.execute_reply":"2022-05-18T05:45:04.291449Z"},"trusted":true},"execution_count":264,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0   0.999248  0.922629  0.959411     28822\n           1   0.002237  0.200000  0.004425        25\n\n    accuracy                       0.922002     28847\n   macro avg   0.500743  0.561314  0.481918     28847\nweighted avg   0.998384  0.922002  0.958584     28847\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\npca = PCA(n_components=100)\npca.fit(X1)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:45:04.297605Z","iopub.execute_input":"2022-05-18T05:45:04.298374Z","iopub.status.idle":"2022-05-18T05:45:10.990042Z","shell.execute_reply.started":"2022-05-18T05:45:04.298317Z","shell.execute_reply":"2022-05-18T05:45:10.989172Z"},"trusted":true},"execution_count":265,"outputs":[{"execution_count":265,"output_type":"execute_result","data":{"text/plain":"PCA(n_components=100)"},"metadata":{}}]},{"cell_type":"code","source":"print(pca.explained_variance_ratio_)\nplt.plot(range(1, 101), pca.explained_variance_ratio_)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:45:10.995905Z","iopub.execute_input":"2022-05-18T05:45:10.998598Z","iopub.status.idle":"2022-05-18T05:45:11.322751Z","shell.execute_reply.started":"2022-05-18T05:45:10.998530Z","shell.execute_reply":"2022-05-18T05:45:11.321737Z"},"trusted":true},"execution_count":266,"outputs":[{"name":"stdout","text":"[0.1184122  0.08757355 0.08256502 0.06303466 0.05807174 0.05182737\n 0.04589581 0.04023639 0.03050746 0.02683931 0.02487024 0.02241323\n 0.01671828 0.01539632 0.01459655 0.01407999 0.01286237 0.01264027\n 0.01179736 0.01060628 0.01039183 0.00934061 0.0089244  0.00803285\n 0.0078277  0.00762898 0.00713456 0.0067908  0.00650651 0.00641141\n 0.00633827 0.00567782 0.00560482 0.00529556 0.00508268 0.00497943\n 0.00480223 0.00451047 0.00435448 0.00416691 0.00391009 0.0036076\n 0.00352139 0.00327398 0.00324889 0.00309274 0.00300788 0.00287607\n 0.00275487 0.00256176 0.00245409 0.00238109 0.00227462 0.00226559\n 0.00214736 0.00209371 0.00207893 0.00201299 0.00192668 0.00184083\n 0.00182288 0.00174037 0.00166379 0.00160908 0.00153532 0.00152663\n 0.00143469 0.00141353 0.0013364  0.00131884 0.00127766 0.00123716\n 0.0011632  0.00114312 0.00110027 0.0010893  0.00100596 0.00100408\n 0.00097331 0.00095753 0.00091114 0.00090206 0.00085735 0.00084591\n 0.00083448 0.00081035 0.00077101 0.00074813 0.00073437 0.0007161\n 0.00069208 0.00068339 0.00066756 0.00062995 0.0006087  0.00058432\n 0.0005674  0.00054318 0.00052428 0.00051941]\n","output_type":"stream"},{"execution_count":266,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7ff0c95e35d0>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfeklEQVR4nO3dfZRcdZ3n8fe3Hvu5k3Q6T52QRJIYGhCCbURRdGDQxHGJsDiAM4ge9uDuDjszy+xx486u4zB/7LI7K7pHnCOKI+oqMshoRlEEQXFRMJ3wmIQknQB5JOk8dbo7/VAP3/3j3k6KokMqSXdX163P65ycVN37q6rvzYXP71e/W/dec3dERCS6YuUuQERExpeCXkQk4hT0IiIRp6AXEYk4Bb2ISMQlyl1AsenTp/uCBQvKXYaISEVZt27dAXdvHW3dpAv6BQsW0NnZWe4yREQqipm9drJ1mroREYk4Bb2ISMSVFPRmtsLMNptZl5mtHmX95Wa23syyZnZdwfKLzex3ZrbBzF4ws+vHsngRETm1Uwa9mcWBu4GVQDtwo5m1FzXbAXwK+F7R8mPAJ939fGAF8CUzm3KWNYuIyGko5WDscqDL3bcDmNn9wCpg40gDd381XJcvfKG7byl4vMfM9gOtwJGzLVxEREpTytRNG7Cz4PmucNlpMbPlQArYdrqvFRGRMzchB2PNbDbwHeDT7p4fZf2tZtZpZp3d3d0TUZKISNUoJeh3A/MKns8Nl5XEzJqAnwJ/7e5Pj9bG3e9x9w5372htHfX3/qfUO5jhrke38NzOI2f0ehGRqCol6NcCi81soZmlgBuANaW8edj+n4Fvu/uDZ17mqeXyzpd/uZX1rx0ez48REak4pwx6d88CtwGPAJuAB9x9g5ndYWZXA5jZu8xsF/Bx4GtmtiF8+R8DlwOfMrPnwj8Xj8eGNKSD48q9g9nxeHsRkYpV0iUQ3P1h4OGiZZ8veLyWYEqn+HXfBb57ljWWJBGPUZeK0zuYmYiPExGpGJE6M7axJsFRBb2IyBtEKuibapKauhERKRKpoG+sSSjoRUSKRCzok5qjFxEpErGg14heRKRYxII+qYOxIiJFIhX0TbUJjmpELyLyBtEK+pokw9k8Q9lcuUsREZk0IhX0jTU6O1ZEpFgkg/7ogObpRURGRCvo00lAI3oRkUKRCvqmWgW9iEixSAX9iTl6Td2IiIyIaNBrRC8iMiJiQR9M3eikKRGRE6IV9OkEZuikKRGRApEK+ljMaEglNEcvIlIgUkEPurCZiEixCAZ9UidMiYgUiGDQa0QvIlIockHfVJukd0gjehGREZELeo3oRUTeKJJBrzl6EZETIhj0SXoHs7h7uUsREZkUIhj0CbJ5ZzCTL3cpIiKTQklBb2YrzGyzmXWZ2epR1l9uZuvNLGtm1xWtu9nMtoZ/bh6rwk+mqWbkCpaavhERgRKC3sziwN3ASqAduNHM2oua7QA+BXyv6LXTgL8B3g0sB/7GzKaefdknd/zmIzogKyIClDaiXw50uft2dx8G7gdWFTZw91fd/QWgeL7kw8Cj7n7I3Q8DjwIrxqDuk2rShc1ERN6glKBvA3YWPN8VLitFSa81s1vNrNPMOru7u0t869HpUsUiIm80KQ7Guvs97t7h7h2tra1n9V4n7jKlEb2ICJQW9LuBeQXP54bLSnE2rz0jGtGLiLxRKUG/FlhsZgvNLAXcAKwp8f0fAT5kZlPDg7AfCpeNm+M3H9FJUyIiQAlB7+5Z4DaCgN4EPODuG8zsDjO7GsDM3mVmu4CPA18zsw3haw8Bf0fQWawF7giXjZv6VJyYaUQvIjIiUUojd38YeLho2ecLHq8lmJYZ7bXfBL55FjWeFjOjIa2bj4iIjJgUB2PHWlNtUiN6EZFQJIO+sSapE6ZEREIRDfqETpgSEQlFMuibdE16EZHjIhn0waWKNaIXEYGIBr1G9CIiJ0Qy6EdG9Lr5iIhIZIM+Qd6hfzhX7lJERMouokGvC5uJiIyIaNDrwmYiIiMiGfS6VLGIyAmRDPrjtxMc0IheRCSSQd90/L6xGtGLiEQy6E8cjNWIXkQkkkE/coPwHt18REQkmkFfk4yxoKWO/7f1QLlLEREpu0gGvZlxzbK5PP3KQXYfGSh3OSIiZRXJoAe4Zlkb7vCjZ8f1XuQiIpNeZIP+nJY63rVgKg+t36Vr3ohIVYts0ANce8lctnX38+LunnKXIiJSNpEO+o9cOJtUIsZD6zV9IyLVK9JB31yb5Kr2max5fg+ZXL7c5YiIlEWkgx7g2mVtHOof5tebu8tdiohIWUQ+6C9f0kpDOsGTWxX0IlKdSgp6M1thZpvNrMvMVo+yPm1mPwjXP2NmC8LlSTO7z8xeNLNNZva5Ma7/lJLxGLOba9h/dGiiP1pEZFI4ZdCbWRy4G1gJtAM3mll7UbNbgMPuvgi4C7gzXP5xIO3uFwLvBD4z0glMpNbGNN19CnoRqU6ljOiXA13uvt3dh4H7gVVFbVYB94WPHwSuNDMDHKg3swRQCwwDR8ek8tPQ2pimu1dBLyLVqZSgbwN2FjzfFS4btY27Z4EeoIUg9PuBvcAO4O/d/dBZ1nzaWhuCoNeJUyJSjcb7YOxyIAfMARYCf2VmbytuZGa3mlmnmXV2d4/9QdPWxjQDmZxuFi4iVamUoN8NzCt4PjdcNmqbcJqmGTgIfAL4ubtn3H0/8BTQUfwB7n6Pu3e4e0dra+vpb8UptDamATR9IyJVqZSgXwssNrOFZpYCbgDWFLVZA9wcPr4OeNyDeZIdwBUAZlYPXAq8PBaFnw4FvYhUs1MGfTjnfhvwCLAJeMDdN5jZHWZ2ddjsXqDFzLqA24GRn2DeDTSY2QaCDuMf3f2Fsd6IU1HQi0g1S5TSyN0fBh4uWvb5gseDBD+lLH5d32jLJ1prw0jQD5a5EhGRiRf5M2MBptalSMRMv6UXkapUFUEfixnTG/RbehGpTlUR9KCTpkSkelVX0GvqRkSqUPUEvaZuRKRKVU/QN6Y50DdMPq/LIIhIdamqoM/lnUPHhstdiojIhKqqoAedNCUi1UdBLyIScdUT9A0KehGpTtUT9CMjev3EUkSqTNUEfX06QV0qrhG9iFSdqgl60NmxIlKdqivoddKUiFSh6gp6XQZBRKpQ9QW9RvQiUmWqK+gb0vQMZBjK6ibhIlI9qivow59YHujTZRBEpHpUZdBr+kZEqomCXkQk4hT0IiIRV1VB31KvoBeR6lNVQZ9KxJhal2R/72C5SxERmTBVFfQAS2Y28vT2g7jrTlMiUh2qLug/tqyNbd39vLCrp9yliIhMiJKC3sxWmNlmM+sys9WjrE+b2Q/C9c+Y2YKCde8ws9+Z2QYze9HMasaw/tP2R++YTToR44frd5WzDBGRCXPKoDezOHA3sBJoB240s/aiZrcAh919EXAXcGf42gTwXeDfuvv5wAeBzJhVfwaaapJ86PxZrHl+j86QFZGqUMqIfjnQ5e7b3X0YuB9YVdRmFXBf+PhB4EozM+BDwAvu/jyAux9097Kn67WXtHHkWIYnXu4udykiIuOulKBvA3YWPN8VLhu1jbtngR6gBVgCuJk9Ymbrzeyzo32Amd1qZp1m1tndPf7h+/5F02ltTGv6RkSqwngfjE0A7wP+JPz7GjO7sriRu9/j7h3u3tHa2jrOJUEiHuOaZW088fJ+DuqyxSIScaUE/W5gXsHzueGyUduE8/LNwEGC0f+T7n7A3Y8BDwOXnG3RY+HaS9rI5p1/eX5PuUsRERlXpQT9WmCxmS00sxRwA7CmqM0a4Obw8XXA4x78UP0R4EIzqws7gA8AG8em9LOzdFYT7bObWKOgF5GIO2XQh3PutxGE9ibgAXffYGZ3mNnVYbN7gRYz6wJuB1aHrz0MfJGgs3gOWO/uPx3zrThDV7XP5NmdRzjUr8sWi0h02WQ7Q7Sjo8M7Ozsn5LOe33mEVXc/xV3XX8Q1y+ZOyGeKiIwHM1vn7h2jrau6M2MLXdjWzPSGNI/rZ5YiEmFVHfSxmPHBt7fy6837yeby5S5HRGRcVHXQA1yxdAZHB7Ose+1wuUsRERkXVR/071s8nUTMeHzz/nKXIiIyLqo+6JtqkrxrwTSeeFlBLyLRVPVBD8H0zZZ9few6fKzcpYiIjDkFPfAHS2cAaFQvIpGkoAfOba1nfksdjyvoRSSCFPSAmXHF0hk8te0g/UPZcpcjIjKmFPShq9pnMpzN8+QWnTwlItGioA8tXzCN5tokj27cV+5SRETGlII+lIjHuHLpDB7XWbIiEjEK+gJXtc/kyLEMa1/VWbIiEh0K+gKXL2kllYhp+kZEIkVBX6A+neCyc1t4dNPrTLbLN4uInCkFfZEPnT+LnYcG2Lyvt9yliIiMCQV9kSvPm4EZPLpB0zciEg0K+iIzGmu4eN4UfqF5ehGJCAX9KD58/ixe3N2ji5yJSCQo6Eex8oJZAPz8pdfLXImIyNlT0I9ifks9581uUtCLSCQo6E9i5QWzWLfjMPuPDpa7FBGRs6KgP4mVF8zCHR7ZoFG9iFQ2Bf1JLJrRwNta6/mZpm9EpMIp6E/CzFh5wSyeeeUQh/qHy12OiMgZKynozWyFmW02sy4zWz3K+rSZ/SBc/4yZLShaf46Z9ZnZfxqjuifEygtmk8s7j27UqF5EKtcpg97M4sDdwEqgHbjRzNqLmt0CHHb3RcBdwJ1F678I/Ozsy51Y589pYu7UWk3fiEhFK2VEvxzocvft7j4M3A+sKmqzCrgvfPwgcKWZGYCZfQx4BdgwJhVPIDPjqvaZ/HbbQTK6Rr2IVKhSgr4N2FnwfFe4bNQ27p4FeoAWM2sA/jPwt2/1AWZ2q5l1mllnd/fkupXfRXOnMJzNs727v9yliIickfE+GPsF4C5373urRu5+j7t3uHtHa2vrOJd0es6f0wTAxr09Za5EROTMlBL0u4F5Bc/nhstGbWNmCaAZOAi8G/ifZvYq8JfAfzGz286u5Im1cHo96USMDbuPlrsUEZEzkiihzVpgsZktJAj0G4BPFLVZA9wM/A64Dnjcgzt3vH+kgZl9Aehz96+MQd0TJhGPsXRWIxv3KuhFpDKdckQfzrnfBjwCbAIecPcNZnaHmV0dNruXYE6+C7gdeNNPMCtZ+5wmNu49qrtOiUhFKmVEj7s/DDxctOzzBY8HgY+f4j2+cAb1TQrtc5r5/u93srdnkDlTastdjojIadGZsSVonx0ckN2wR9M3IlJ5FPQlWDqrETPYqKAXkQqkoC9BfTrBwpZ6/cRSRCqSgr5EIwdkRUQqjYK+RO1zmth5aICegUy5SxEROS0K+hKNHJDdpFG9iFQYBX2J2kcuhaADsiJSYRT0JZrRWENrY1rz9CJScRT0p6F9dpNG9CJScRT0p+H8OU1s3d/Lwb6hcpciIlIyBf1puPaSuWTzztd/80q5SxERKZmC/jQsmtHA1RfN4du/e1WjehGpGAr60/QfrljMQCanUb2IVAwF/WnSqF5EKo2C/gxoVC8ilURBfwZGRvX3/fZVNr/eW+5yRETekoL+DH12xVIaaxLcdO8z7Dh4rNzliIiclIL+DLVNqeW7/+bdDOfy/Om9z7D/6GC5SxIRGZWC/iwsmdnItz69nAN9Q9x07+/pHdSVLUVk8lHQn6WL503h65/soKu7j8899KJuIC4ik46Cfgxctmg6t1+1hJ+8sJfv/X5HucsREXkDBf0Y+XcfOJfLl7Tyt/+yURc+E5FJRUE/RmIx44t/fBFT65Lc9r31HBvOlrskERFAQT+mpjek+V/XXcT2A/387MXXy12OiAhQYtCb2Qoz22xmXWa2epT1aTP7Qbj+GTNbEC6/yszWmdmL4d9XjHH9k877F09nTnMNP9+goBeRyeGUQW9mceBuYCXQDtxoZu1FzW4BDrv7IuAu4M5w+QHgX7n7hcDNwHfGqvDJysz48AWzeHJLN/1Dmr4RkfIrZUS/HOhy9+3uPgzcD6wqarMKuC98/CBwpZmZuz/r7nvC5RuAWjNLj0Xhk9mK82cxlM3zq83d5S5FRKSkoG8DdhY83xUuG7WNu2eBHqClqM2/Bta7+5su+Whmt5pZp5l1dndXfjh2LJjG9IYUP3tpb7lLERGZmIOxZnY+wXTOZ0Zb7+73uHuHu3e0trZOREnjKh4zrmqfxRMv72cwkyt3OSJS5UoJ+t3AvILnc8Nlo7YxswTQDBwMn88F/hn4pLtvO9uCK8WKC2bRP5zjqa4D5S5FRKpcKUG/FlhsZgvNLAXcAKwparOG4GArwHXA4+7uZjYF+Cmw2t2fGqOaK8J73tZCU02Cn72kX9+ISHmdMujDOffbgEeATcAD7r7BzO4ws6vDZvcCLWbWBdwOjPwE8zZgEfB5M3su/DNjzLdiEkolYvzheTN5bNM+Mrl8ucsRkSpmk+0iXB0dHd7Z2VnuMsbEIxte5zPfWce//+C53H7VEhJxnZ8mIuPDzNa5e8do65Q84+jKpTO4ZlkbX/3VNm78+tPsPjJQ7pJEpAop6MdRIh7jrusv5q7rL2LjnqOs/NKTfPVXXRzuHy53aSJSRTR1M0FeO9jPf/3RS/xm6wFqkjGuWTaXVRfP4Z3zp5LUlI6InKW3mrpR0E+wza/38q3fvsJD63czlM3TkE7w3nNb+PRlC3nPucXnmImIlEZBPwn1Dmb47baD/HpLN7/ctI99R4e46dL5rF65lPp0otzliUiFUdBPcgPDOf73LzZz71OvMKe5lj+9dD5zp9bSNrWWpbMaqUsp+EXkrSnoK8S61w6x+ocvsnV/3/FlzbVJbrp0Pje/dwGtjZG/HpyInCEFfYXpHcyw+8gArx08xkPrd/GLjftIxmPcdOl8br9qiaZ2RORNFPQVbnt3H1/79XYeWLeTOc21/PdrL+TyJZV/8TcRGTsK+ojofPUQn/3hC2zv7ue957awcHo9c6bUctHcKVy2qAUzK3eJIlImCvoIGczk+OoTXTy2aT97ewY4fCwDwGWLWvhvH21n6aymMlcoIuWgoI+w/qEs/9S5k7se20rvYIaPLWvj/Yun0zF/GnOn1mqUL1IlFPRV4HD/MF96bAs/XL+bvvBetW1TarnlfQu5cfk51KbiZa5QRMaTgr6K5PLOln29rHvtMGue38PvXznE9IYUN126gLfPamTOlBpmN9fSUp8iFtNoXyQqFPRV7JntB/nKE138Zusb73SVjBszm2qYM6WWdy2YyvsWtXLJ/CmkExr5i1QiBb1wsG+IvT2D7DkywN6eQV4/OsjrPYO8erCfF3b1kMs7tck4581upH1OE+fNbmLJzEbObW1gWn2q3OWLyCm8VdDrzJsq0dKQpqUhzQVtzW9a1zuY4enth/jttgNs2HOUHz+7h+8+veP4+il1SVrqUzTUJGlIx6lLJahNxqlNxmmf08RH3zGblgadtSsyWWlEL2/i7uw6PEBXdx/b9vfxyoF+jhzL0DuUpX8oy7HhHAPDWfqGchzoGyIeMz6wpJWOBVOpSwYdQUtDiiUzG2mbUqtjASITQCN6OS1mxrxpdcybVscfvP2tb/H78utH+dGze/jxc7t5/OX9b1pfm4wfP7GrbUoNM5pqaKxJ0FiToLk2SWtDDTOa0rTUp3SrRZFxohG9jAl3Zyib59hwjmPDWfYdHWTLvj627OvllQP97D0yyJ6eAXoHs6O+PhEzzmmpY1FrA29rbaC1MQj/loYUM5tqmNlYQ1NtQucFiJyERvQy7syMmmScmmScafUp5k6t453zp72p3WAmR+9glr6hLIePDdPdO0R37xB7jgywrbuPbd39PLF5P5ncmwcgNckY50yr45xp9SxoqWPRjAYWz2xg0YxGmmuTE7GZIhVJQS8TaqQzaG1Ms5D6Udu4O0cHshzoDzqB/b1D7D86yN6eQXYcOsZrB/v5zdZuhrL5469Jxo26VIL6VJwZTTXMb6njnGl1NNUkiceMRNyoTyWY1pBien2aKXVJ6lJx6tMJ0omYvilIpCnoZdIxM5rrkjTXJTm3tWHUNvm8s/vIAFv29dK1v4+egQzHhnP0DWXZ2zPA+h2H+ckLe8nlTz01mYgZU+qSNNcmmVKXork2eDy1LsXMpjSzmmtobUzTVJOksSZBQzpBXSpBTVIdhFQGBb1UpFjsxAHjK8+bOWqbTC7PYCZHLu9k807fYJaD/UMc6BvmaNgxHBvOcXQww5FjGXoGhjncnwmPL/RyuH+Y/uHcW9ZRl4rTkE4c7wBiMSNmRsygIZ2gqTZJU02S2lScdCJGKh4jHj/RJhmPURt+y6lNxalPJahLh3+H3zhSiRhxM2IxSMZi+hWTnDYFvURWMh4jWfBLnukNaRZMH3266GR6B4Pg3987RO9gNji+MJhhIJNnIJPj2FBwvGHkuEPeHffgUhQH+obZ1t3P0cEMg5kcQ9k8Y/Hbh5pkjPpUgtpUcC5DXSroKNLJoDNJJ4LOozZcbgaGEY9xfHqrLp0gGXY48ZhRkwjfJxUnGYthRjDlFbPg3zERIxk3UuG/aToR06+kKkhJQW9mK4AvA3HgG+7+P4rWp4FvA+8EDgLXu/ur4brPAbcAOeDP3f2RMateZJw11iRprEmyaEbjWb+Xe/DNIpcPOwN3Mtk8g9kcA8O5oOMIp58GhnPHz1kYyubI5SHvznA27GCGsxwbOvGagUyOowMZhrJ5hjLB84FMjsFMjrwD4eeVMpVVqmQ8OACfigffMuIWHAtJxWMk4kYi7DBGOpP68GS7mmScke8khR1KPBYjHiP8tmMk43a8sx75BmQGiXjwzSgZftMJPiPozEY+LxYjeL+imuJhnfGYveHb18hnxmKE355OtDMLphNH2o18RjIWvGcyHgveL2w3GZ0y6M0sDtwNXAXsAtaa2Rp331jQ7BbgsLsvMrMbgDuB682sHbgBOB+YAzxmZkvc/a2/D4tEkB0Pr4KFE3xC8VA2R/9Q0ImMdDp5dwZHOozhYKor504+nPLK5PLhnxOPh8JvNAOZHMPZPPmwE8nmnEw+6MCy+eAbTD7s4I4N5zjUP8Bg5sT//oWvy+Yddz++bOTzsmPYOY23WNhxjXQoI53JSEdQuHzk8UjfYGYsndXIVz5xyZjXVcqIfjnQ5e7bw2LuB1YBhUG/CvhC+PhB4CsWdG2rgPvdfQh4xcy6wvf73diULyKnI52Ik07EK+r6Rfm84xB2ApDN5xnO5sMOBpxguYfTZvmwXXBsJn+8E8nkgscjHUnOHfxEZ5N/w+OwTdFnn3j/oCPKhh1fLs/xzrGwk8wXLnNGWR7WDeBwzrS6cfk3LCXo24CdBc93Ae8+WRt3z5pZD9ASLn+66LVtxR9gZrcCtwKcc845pdYuIlXgxMHn4O8UMeoqp5+aFCbF0RR3v8fdO9y9o7VVN70WERlLpQT9bmBewfO54bJR25hZAmgmOChbymtFRGQclRL0a4HFZrbQzFIEB1fXFLVZA9wcPr4OeNyDi+isAW4ws7SZLQQWA78fm9JFRKQUp5yjD+fcbwMeIfh55TfdfYOZ3QF0uvsa4F7gO+HB1kMEnQFhuwcIDtxmgT/TL25ERCaWrl4pIhIBb3X1yklxMFZERMaPgl5EJOIU9CIiETfp5ujNrBt47TRfNh04MA7lTGbVuM1QndtdjdsM1bndZ7PN89191BORJl3Qnwkz6zzZQYioqsZthurc7mrcZqjO7R6vbdbUjYhIxCnoRUQiLipBf0+5CyiDatxmqM7trsZthurc7nHZ5kjM0YuIyMlFZUQvIiInoaAXEYm4ig56M1thZpvNrMvMVpe7nvFiZvPM7Akz22hmG8zsL8Ll08zsUTPbGv49tdy1jjUzi5vZs2b2k/D5QjN7JtznPwivqBoZZjbFzB40s5fNbJOZvadK9vN/DP/bfsnMvm9mNVHc12b2TTPbb2YvFSwbdf9a4P+E2/+CmZ3xPQYrNugL7mW7EmgHbgzvURtFWeCv3L0duBT4s3BbVwO/dPfFwC/D51HzF8Cmgud3Ane5+yLgMMH9iqPky8DP3X0pcBHBtkd6P5tZG/DnQIe7X0BwldyRe09HbV9/C1hRtOxk+3clwaXdFxPcge8fzvRDKzboKbiXrbsPAyP3so0cd9/r7uvDx70E//O3EWzvfWGz+4CPlaXAcWJmc4E/Ar4RPjfgCoL7EkPEttnMmoHLCS77jbsPu/sRIr6fQwmgNrxxUR2wlwjua3d/kuBS7oVOtn9XAd/2wNPAFDObfSafW8lBP9q9bN90P9qoMbMFwDLgGWCmu+8NV70OzCxXXePkS8BngXz4vAU44u7Z8HnU9vlCoBv4x3C66htmVk/E97O77wb+HthBEPA9wDqiva8LnWz/jlnGVXLQVx0zawB+CPylux8tXBfe0Ssyv5U1s48C+919XblrmUAJ4BLgH9x9GdBP0TRN1PYzQDgnvYqgo5sD1PPm6Y2qMF77t5KDvqruR2tmSYKQ/7/u/lC4eN/IV7nw7/3lqm8cXAZcbWavEkzLXUEwfz0l/HoP0dvnu4Bd7v5M+PxBguCP8n4G+EPgFXfvdvcM8BDB/o/yvi50sv07ZhlXyUFfyr1sIyGcm74X2OTuXyxYVXiv3puBH090bePF3T/n7nPdfQHBvn3c3f8EeILgvsQQvW1+HdhpZm8PF11JcBvOyO7n0A7gUjOrC/9bH9nuyO7rIifbv2uAT4a/vrkU6CmY4jk97l6xf4CPAFuAbcBfl7uecdzO9xF8nXsBeC788xGCOetfAluBx4Bp5a51nLb/g8BPwsdvI7jBfBfwT0C63PWN8bZeDHSG+/pHwNRq2M/A3wIvAy8B3wHSUdzXwPcJjkNkCL7B3XKy/QsYwS8LtwEvEvwq6Yw+V5dAEBGJuEqeuhERkRIo6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOIU9CIiEff/AQXojlTczrtOAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"X1_reduced = pca.transform(X1)\nX1_train, X1_test, y_train, y_test = train_test_split(\n    X1_reduced, y, test_size = 0.2, random_state = 0)\nclf.fit(X1_train, y_train)\nprint(classification_report(clf.predict(X1_test), y_test, digits = 6))\n# accuracy decreased","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:45:17.896500Z","iopub.execute_input":"2022-05-18T05:45:17.897159Z","iopub.status.idle":"2022-05-18T05:45:19.559601Z","shell.execute_reply.started":"2022-05-18T05:45:17.897118Z","shell.execute_reply":"2022-05-18T05:45:19.556756Z"},"trusted":true},"execution_count":267,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0   0.924808  0.922140  0.923472     26689\n           1   0.070246  0.072753  0.071477      2158\n\n    accuracy                       0.858599     28847\n   macro avg   0.497527  0.497446  0.497475     28847\nweighted avg   0.860880  0.858599  0.859736     28847\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\nX1_train, X1_test, y_train, y_test = train_test_split(\n    X1_reduced, y, test_size = 0.2, random_state = 0)\nlda.fit(X1_train, y_train)\nprint(classification_report( lda.predict(X1_test), y_test, digits = 6))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:45:22.294520Z","iopub.execute_input":"2022-05-18T05:45:22.294808Z","iopub.status.idle":"2022-05-18T05:45:26.148473Z","shell.execute_reply.started":"2022-05-18T05:45:22.294777Z","shell.execute_reply":"2022-05-18T05:45:26.147583Z"},"trusted":true},"execution_count":268,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0   0.999136  0.922653  0.959372     28818\n           1   0.002685  0.206897  0.005300        29\n\n    accuracy                       0.921933     28847\n   macro avg   0.500910  0.564775  0.482336     28847\nweighted avg   0.998134  0.921933  0.958413     28847\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TASK 2","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:16.306190Z","iopub.execute_input":"2022-05-18T04:10:16.306915Z","iopub.status.idle":"2022-05-18T04:10:16.316016Z","shell.execute_reply.started":"2022-05-18T04:10:16.306869Z","shell.execute_reply":"2022-05-18T04:10:16.314975Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"# Here I am reading the train and test data\ntrain = pd.read_csv('../input/task2data/UNSW_NB15_testing-set.csv')\ntest = pd.read_csv('../input/task2data/UNSW_NB15_training-set.csv')\ndf = pd.concat([train, test])\ncat_feats = df.select_dtypes(['object']).columns","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:19.921306Z","iopub.execute_input":"2022-05-18T04:10:19.921610Z","iopub.status.idle":"2022-05-18T04:10:21.083233Z","shell.execute_reply.started":"2022-05-18T04:10:19.921576Z","shell.execute_reply":"2022-05-18T04:10:21.082448Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"# Here I am encoding the categorical features\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nfor feature in cat_feats:\n    df[feature] = le.fit_transform(df[feature])","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:23.505123Z","iopub.execute_input":"2022-05-18T04:10:23.505983Z","iopub.status.idle":"2022-05-18T04:10:23.821287Z","shell.execute_reply.started":"2022-05-18T04:10:23.505916Z","shell.execute_reply":"2022-05-18T04:10:23.820451Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"# Here I am finding the columns which have almost same values\nsame_val_columns = []\nfor col in df.columns:\n    val, counts = np.unique(df[col],return_counts=True)\n    v = counts[0] / counts.sum()\n    if v > 0.95:\n        same_val_columns.append(col)\n\nsame_val_columns\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:26.649167Z","iopub.execute_input":"2022-05-18T04:10:26.649835Z","iopub.status.idle":"2022-05-18T04:10:27.059734Z","shell.execute_reply.started":"2022-05-18T04:10:26.649799Z","shell.execute_reply":"2022-05-18T04:10:27.059058Z"},"trusted":true},"execution_count":205,"outputs":[{"execution_count":205,"output_type":"execute_result","data":{"text/plain":"['is_ftp_login', 'ct_ftp_cmd', 'is_sm_ips_ports']"},"metadata":{}}]},{"cell_type":"code","source":"# Here I am splitting the data\nx_train = df.iloc[:len(train)]\nx_test = df.iloc[len(train):]","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:30.034174Z","iopub.execute_input":"2022-05-18T04:10:30.034874Z","iopub.status.idle":"2022-05-18T04:10:30.039087Z","shell.execute_reply.started":"2022-05-18T04:10:30.034839Z","shell.execute_reply":"2022-05-18T04:10:30.038069Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"# Here I am removing the columns which have almost all same values\nx_train.drop(same_val_columns, inplace = True, axis = 1)\nx_test.drop(same_val_columns, inplace = True, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:32.890178Z","iopub.execute_input":"2022-05-18T04:10:32.891032Z","iopub.status.idle":"2022-05-18T04:10:32.983904Z","shell.execute_reply.started":"2022-05-18T04:10:32.890973Z","shell.execute_reply":"2022-05-18T04:10:32.983123Z"},"trusted":true},"execution_count":207,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n","output_type":"stream"}]},{"cell_type":"code","source":"# Here I am extracting the labels\ny_train = x_train[\"attack_cat\"]\ny_test = x_test[\"attack_cat\"]\n\nx_train.drop(\"attack_cat\", inplace = True, axis = 1)\nx_test.drop(\"attack_cat\", inplace = True, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:36.220820Z","iopub.execute_input":"2022-05-18T04:10:36.221436Z","iopub.status.idle":"2022-05-18T04:10:36.261538Z","shell.execute_reply.started":"2022-05-18T04:10:36.221395Z","shell.execute_reply":"2022-05-18T04:10:36.260675Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"# Here I am converting to numpy and scaling using a standard scale\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train.to_numpy())\nx_test = scaler.transform(x_test.to_numpy())\ny_train = y_train.to_numpy(dtype=int)\ny_test = y_test.to_numpy(dtype=int)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:39.397471Z","iopub.execute_input":"2022-05-18T04:10:39.398052Z","iopub.status.idle":"2022-05-18T04:10:39.551576Z","shell.execute_reply.started":"2022-05-18T04:10:39.397962Z","shell.execute_reply":"2022-05-18T04:10:39.550838Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"# Here I am converting into torch\nx_train, x_test, y_train, y_test = torch.Tensor(x_train), torch.Tensor(x_test),torch.tensor(y_train, dtype=torch.int64), torch.tensor(y_test, dtype=torch.int64)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:42.159887Z","iopub.execute_input":"2022-05-18T04:10:42.160139Z","iopub.status.idle":"2022-05-18T04:10:42.178317Z","shell.execute_reply.started":"2022-05-18T04:10:42.160111Z","shell.execute_reply":"2022-05-18T04:10:42.177596Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"# Here I am creating data loaders\ntrain_loader = DataLoader(TensorDataset(x_train, y_train), batch_size = 64, shuffle = True)\ntest_loader = DataLoader(TensorDataset(x_test, y_test), batch_size = 64, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:45.074211Z","iopub.execute_input":"2022-05-18T04:10:45.074838Z","iopub.status.idle":"2022-05-18T04:10:45.079310Z","shell.execute_reply.started":"2022-05-18T04:10:45.074801Z","shell.execute_reply":"2022-05-18T04:10:45.078604Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"# Here I am creating Generator and Discriminator classes\nclass Generator(nn.Module):\n    def __init__(self,output_dim, noise_dim=32):\n        super(Generator, self).__init__()\n        input_out_feats = 64\n        emb_dim = 23\n        self.input_layer = nn.Linear(in_features = noise_dim, out_features = input_out_feats)\n        self.emb_y = nn.Sequential(\n            nn.Embedding(num_embeddings = 10,embedding_dim = emb_dim), \n            nn.Flatten()\n        )\n        self.model = nn.Sequential( \n            nn.Linear(input_out_feats + emb_dim, 128), \n            nn.ReLU(),                      \n            nn.Linear(128, 256), \n            nn.ReLU(),                   \n            nn.Linear(256, 512), \n            nn.ReLU(),              \n            nn.Linear(512, output_dim), \n            nn.Tanh()\n        )\n        \n    def forward(self, x, y):\n         x = self.input_layer(x)\n         y = self.emb_y(y)\n         return self.model(torch.cat((x, y), dim = 1))\n        \n        \nclass Discriminator(nn.Module):\n    def __init__(self,input_size):\n        super(Discriminator, self).__init__()\n        emb_dim = 23\n        self.emb_y = nn.Sequential(\n            nn.Embedding(num_embeddings = 10,embedding_dim = emb_dim),\n            nn.Flatten()\n        )\n        self.model = nn.Sequential(nn.Linear(input_size + emb_dim, 512), \n                                   nn.LeakyReLU(),\n                                   nn.Linear(512, 256), \n                                   nn.LeakyReLU(),\n                                   nn.Linear(256, 128), \n                                   nn.LeakyReLU(),\n                                   nn.Linear(128, 1), \n                                   nn.Sigmoid()\n                                  )\n\n    def forward(self, x, y):\n        y = self.emb_y(y)\n        return self.model(torch.cat((x, y),dim = 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:48.790148Z","iopub.execute_input":"2022-05-18T04:10:48.790475Z","iopub.status.idle":"2022-05-18T04:10:48.805499Z","shell.execute_reply.started":"2022-05-18T04:10:48.790442Z","shell.execute_reply":"2022-05-18T04:10:48.803780Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"# Here I am assigning gen and dis objects and optimizers\nD = Discriminator(input_size = 41).to(device).float()\nG = Generator(output_dim = 41, noise_dim = 32).to(device).float()\nloss_module = nn.BCELoss()\nd_optimizer = optim.SGD(D.parameters(), learning_rate)\ng_optimizer = optim.SGD(G.parameters(), learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:53.512472Z","iopub.execute_input":"2022-05-18T04:10:53.513094Z","iopub.status.idle":"2022-05-18T04:10:53.528840Z","shell.execute_reply.started":"2022-05-18T04:10:53.513054Z","shell.execute_reply":"2022-05-18T04:10:53.528124Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"# Here I am creating loss functions\ndef real_loss(D_out):\n    batch_size = D_out.size(0)\n    labels = torch.FloatTensor(batch_size).uniform_(0.9, 1).to(device)\n    loss_fn = nn.BCELoss()\n    loss = loss_fn(D_out.squeeze(), labels)\n    return loss\n\ndef fake_loss(D_out):\n    batch_size = D_out.size(0)\n    labels = torch.FloatTensor(batch_size).uniform_(0, 0.1).to(device)\n    loss_fn = nn.BCELoss()\n    loss = loss_fn(D_out.squeeze(), labels)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:10:56.678719Z","iopub.execute_input":"2022-05-18T04:10:56.678979Z","iopub.status.idle":"2022-05-18T04:10:56.685370Z","shell.execute_reply.started":"2022-05-18T04:10:56.678951Z","shell.execute_reply":"2022-05-18T04:10:56.684479Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"# Here I am training the GAN\nnum_epochs = 500\nz_size = 32\n\nlosses = []\n\nfor epoch in range(num_epochs):\n\n    for batch_index, (X, y) in enumerate(train_loader):\n\n        batch_size = X.size(0)\n        z = np.random.uniform(0, 1, size = (batch_size, z_size))\n        z = torch.from_numpy(z).float().to(device)\n        \n        d_optimizer.zero_grad()\n        \n        X = X.to(device)\n        y = y.to(device)\n        \n        d_real = D(X, y)\n        d_loss = real_loss(d_real)\n        \n        g_fake = G(z, y)\n        d_fake = D(g_fake, y)\n        \n        d_loss = d_loss + fake_loss(d_fake)\n        d_loss.backward()\n        \n        d_optimizer.step()\n        g_optimizer.zero_grad()\n        \n        g_fake = G(z, y)\n        g_loss = real_loss(D(g_fake, y))\n        \n        g_loss.backward()\n        g_optimizer.step()\n            \n    print('epoch [{}/{}], d_loss: {:6.4f} | g_loss: {:6.4f}'.format(epoch + 1, num_epochs, d_loss.item(), g_loss.item()))\n    losses.append((d_loss.item(), g_loss.item()))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-18T01:16:34.260462Z","iopub.execute_input":"2022-05-18T01:16:34.260716Z","iopub.status.idle":"2022-05-18T03:24:02.874623Z","shell.execute_reply.started":"2022-05-18T01:16:34.260682Z","shell.execute_reply":"2022-05-18T03:24:02.873799Z"},"trusted":true},"execution_count":181,"outputs":[{"name":"stdout","text":"epoch [1/500], d_loss: 1.2877 | g_loss: 0.6900\nepoch [2/500], d_loss: 1.0902 | g_loss: 0.7575\nepoch [3/500], d_loss: 0.7080 | g_loss: 1.1441\nepoch [4/500], d_loss: 0.7518 | g_loss: 1.4317\nepoch [5/500], d_loss: 0.6209 | g_loss: 1.9570\nepoch [6/500], d_loss: 0.6218 | g_loss: 2.1678\nepoch [7/500], d_loss: 0.5249 | g_loss: 1.9348\nepoch [8/500], d_loss: 0.4421 | g_loss: 2.2809\nepoch [9/500], d_loss: 0.4895 | g_loss: 2.1976\nepoch [10/500], d_loss: 0.4252 | g_loss: 2.6557\nepoch [11/500], d_loss: 0.4205 | g_loss: 2.7285\nepoch [12/500], d_loss: 0.4848 | g_loss: 2.7081\nepoch [13/500], d_loss: 0.4083 | g_loss: 2.7500\nepoch [14/500], d_loss: 0.4131 | g_loss: 2.7608\nepoch [15/500], d_loss: 0.4308 | g_loss: 2.1809\nepoch [16/500], d_loss: 0.4103 | g_loss: 2.6690\nepoch [17/500], d_loss: 0.4625 | g_loss: 2.4345\nepoch [18/500], d_loss: 1.0832 | g_loss: 1.2225\nepoch [19/500], d_loss: 0.7717 | g_loss: 1.5227\nepoch [20/500], d_loss: 0.7676 | g_loss: 1.5767\nepoch [21/500], d_loss: 0.6686 | g_loss: 1.7055\nepoch [22/500], d_loss: 0.5868 | g_loss: 2.1245\nepoch [23/500], d_loss: 0.7436 | g_loss: 1.6382\nepoch [24/500], d_loss: 0.4376 | g_loss: 2.2889\nepoch [25/500], d_loss: 0.6071 | g_loss: 2.0390\nepoch [26/500], d_loss: 0.4676 | g_loss: 2.2703\nepoch [27/500], d_loss: 0.4836 | g_loss: 2.2326\nepoch [28/500], d_loss: 0.4431 | g_loss: 2.1983\nepoch [29/500], d_loss: 0.4435 | g_loss: 2.6167\nepoch [30/500], d_loss: 0.4775 | g_loss: 2.0731\nepoch [31/500], d_loss: 0.4656 | g_loss: 2.4036\nepoch [32/500], d_loss: 0.4898 | g_loss: 2.2251\nepoch [33/500], d_loss: 0.5733 | g_loss: 2.1250\nepoch [34/500], d_loss: 0.7026 | g_loss: 2.0027\nepoch [35/500], d_loss: 0.5946 | g_loss: 1.9627\nepoch [36/500], d_loss: 0.4962 | g_loss: 1.9491\nepoch [37/500], d_loss: 0.5421 | g_loss: 2.0248\nepoch [38/500], d_loss: 0.6706 | g_loss: 2.0031\nepoch [39/500], d_loss: 0.7389 | g_loss: 1.9418\nepoch [40/500], d_loss: 0.6597 | g_loss: 1.8919\nepoch [41/500], d_loss: 0.6337 | g_loss: 2.0424\nepoch [42/500], d_loss: 0.6881 | g_loss: 1.9890\nepoch [43/500], d_loss: 0.4250 | g_loss: 2.5753\nepoch [44/500], d_loss: 0.7163 | g_loss: 1.9162\nepoch [45/500], d_loss: 0.5759 | g_loss: 1.9594\nepoch [46/500], d_loss: 0.5632 | g_loss: 2.1481\nepoch [47/500], d_loss: 0.7856 | g_loss: 2.0780\nepoch [48/500], d_loss: 0.8982 | g_loss: 1.8277\nepoch [49/500], d_loss: 0.6073 | g_loss: 2.1729\nepoch [50/500], d_loss: 0.5045 | g_loss: 2.1333\nepoch [51/500], d_loss: 0.5317 | g_loss: 2.2677\nepoch [52/500], d_loss: 0.4983 | g_loss: 2.3025\nepoch [53/500], d_loss: 0.6087 | g_loss: 2.0883\nepoch [54/500], d_loss: 0.4585 | g_loss: 2.6550\nepoch [55/500], d_loss: 0.4507 | g_loss: 2.3893\nepoch [56/500], d_loss: 0.4225 | g_loss: 2.8137\nepoch [57/500], d_loss: 0.4364 | g_loss: 2.6218\nepoch [58/500], d_loss: 0.4061 | g_loss: 2.8219\nepoch [59/500], d_loss: 0.4212 | g_loss: 2.7981\nepoch [60/500], d_loss: 0.3934 | g_loss: 2.8319\nepoch [61/500], d_loss: 0.4083 | g_loss: 2.8512\nepoch [62/500], d_loss: 0.4086 | g_loss: 2.7780\nepoch [63/500], d_loss: 0.3825 | g_loss: 2.8203\nepoch [64/500], d_loss: 0.3716 | g_loss: 2.8163\nepoch [65/500], d_loss: 0.4098 | g_loss: 2.7984\nepoch [66/500], d_loss: 0.4099 | g_loss: 2.8199\nepoch [67/500], d_loss: 0.4006 | g_loss: 2.8206\nepoch [68/500], d_loss: 0.4502 | g_loss: 2.8449\nepoch [69/500], d_loss: 0.3685 | g_loss: 2.8351\nepoch [70/500], d_loss: 0.3457 | g_loss: 2.8811\nepoch [71/500], d_loss: 0.3954 | g_loss: 2.8967\nepoch [72/500], d_loss: 0.4022 | g_loss: 2.8437\nepoch [73/500], d_loss: 0.3990 | g_loss: 2.8920\nepoch [74/500], d_loss: 0.3838 | g_loss: 2.8350\nepoch [75/500], d_loss: 0.3882 | g_loss: 2.8374\nepoch [76/500], d_loss: 0.4005 | g_loss: 2.8103\nepoch [77/500], d_loss: 0.4093 | g_loss: 2.7952\nepoch [78/500], d_loss: 0.4329 | g_loss: 2.8225\nepoch [79/500], d_loss: 0.4227 | g_loss: 2.8686\nepoch [80/500], d_loss: 0.3649 | g_loss: 2.8243\nepoch [81/500], d_loss: 0.3983 | g_loss: 2.7965\nepoch [82/500], d_loss: 0.4302 | g_loss: 2.7463\nepoch [83/500], d_loss: 0.3879 | g_loss: 2.8381\nepoch [84/500], d_loss: 0.4111 | g_loss: 2.8482\nepoch [85/500], d_loss: 0.3873 | g_loss: 2.7846\nepoch [86/500], d_loss: 0.4123 | g_loss: 2.8156\nepoch [87/500], d_loss: 0.3984 | g_loss: 2.8581\nepoch [88/500], d_loss: 0.3959 | g_loss: 2.8533\nepoch [89/500], d_loss: 0.3982 | g_loss: 2.8359\nepoch [90/500], d_loss: 0.4200 | g_loss: 2.8598\nepoch [91/500], d_loss: 0.4152 | g_loss: 2.8414\nepoch [92/500], d_loss: 0.3992 | g_loss: 2.8353\nepoch [93/500], d_loss: 0.4451 | g_loss: 2.7938\nepoch [94/500], d_loss: 0.4112 | g_loss: 2.8372\nepoch [95/500], d_loss: 0.4065 | g_loss: 2.8416\nepoch [96/500], d_loss: 0.3995 | g_loss: 2.8654\nepoch [97/500], d_loss: 0.3883 | g_loss: 2.8184\nepoch [98/500], d_loss: 0.3982 | g_loss: 2.8366\nepoch [99/500], d_loss: 0.4082 | g_loss: 2.8294\nepoch [100/500], d_loss: 0.3607 | g_loss: 2.8279\nepoch [101/500], d_loss: 0.4328 | g_loss: 2.8134\nepoch [102/500], d_loss: 0.4057 | g_loss: 2.8417\nepoch [103/500], d_loss: 0.4071 | g_loss: 2.8160\nepoch [104/500], d_loss: 0.3832 | g_loss: 2.8677\nepoch [105/500], d_loss: 0.3786 | g_loss: 2.8526\nepoch [106/500], d_loss: 0.3946 | g_loss: 2.8282\nepoch [107/500], d_loss: 0.4045 | g_loss: 2.8001\nepoch [108/500], d_loss: 0.4047 | g_loss: 2.8299\nepoch [109/500], d_loss: 0.3605 | g_loss: 2.8195\nepoch [110/500], d_loss: 0.3793 | g_loss: 2.8490\nepoch [111/500], d_loss: 0.3747 | g_loss: 2.8667\nepoch [112/500], d_loss: 0.3634 | g_loss: 2.8760\nepoch [113/500], d_loss: 0.4032 | g_loss: 2.8524\nepoch [114/500], d_loss: 0.3949 | g_loss: 2.8391\nepoch [115/500], d_loss: 0.3969 | g_loss: 2.8411\nepoch [116/500], d_loss: 0.3891 | g_loss: 2.8355\nepoch [117/500], d_loss: 0.4113 | g_loss: 2.8399\nepoch [118/500], d_loss: 0.3829 | g_loss: 2.8119\nepoch [119/500], d_loss: 0.3621 | g_loss: 2.8532\nepoch [120/500], d_loss: 0.4255 | g_loss: 2.8428\nepoch [121/500], d_loss: 0.4004 | g_loss: 2.8482\nepoch [122/500], d_loss: 0.4011 | g_loss: 2.8496\nepoch [123/500], d_loss: 0.4275 | g_loss: 2.8630\nepoch [124/500], d_loss: 0.4006 | g_loss: 2.8577\nepoch [125/500], d_loss: 0.3861 | g_loss: 2.8588\nepoch [126/500], d_loss: 0.3869 | g_loss: 2.8657\nepoch [127/500], d_loss: 0.3746 | g_loss: 2.8281\nepoch [128/500], d_loss: 0.3785 | g_loss: 2.8456\nepoch [129/500], d_loss: 0.3686 | g_loss: 2.8560\nepoch [130/500], d_loss: 0.3759 | g_loss: 2.8500\nepoch [131/500], d_loss: 0.3734 | g_loss: 2.8710\nepoch [132/500], d_loss: 0.4336 | g_loss: 2.8070\nepoch [133/500], d_loss: 0.3934 | g_loss: 2.8514\nepoch [134/500], d_loss: 0.3775 | g_loss: 2.8638\nepoch [135/500], d_loss: 0.4060 | g_loss: 2.8346\nepoch [136/500], d_loss: 0.3809 | g_loss: 2.8675\nepoch [137/500], d_loss: 0.3903 | g_loss: 2.7948\nepoch [138/500], d_loss: 0.3647 | g_loss: 2.8357\nepoch [139/500], d_loss: 0.4302 | g_loss: 2.8035\nepoch [140/500], d_loss: 0.4022 | g_loss: 2.8413\nepoch [141/500], d_loss: 0.3904 | g_loss: 2.8318\nepoch [142/500], d_loss: 0.3781 | g_loss: 2.8576\nepoch [143/500], d_loss: 0.4271 | g_loss: 2.8412\nepoch [144/500], d_loss: 0.4118 | g_loss: 2.8266\nepoch [145/500], d_loss: 0.3943 | g_loss: 2.8368\nepoch [146/500], d_loss: 0.4022 | g_loss: 2.8385\nepoch [147/500], d_loss: 0.3949 | g_loss: 2.7874\nepoch [148/500], d_loss: 0.4057 | g_loss: 2.8556\nepoch [149/500], d_loss: 0.3869 | g_loss: 2.8427\nepoch [150/500], d_loss: 0.3658 | g_loss: 2.8327\nepoch [151/500], d_loss: 0.4031 | g_loss: 2.8620\nepoch [152/500], d_loss: 0.3814 | g_loss: 2.8666\nepoch [153/500], d_loss: 0.3897 | g_loss: 2.8648\nepoch [154/500], d_loss: 0.3992 | g_loss: 2.8389\nepoch [155/500], d_loss: 0.3884 | g_loss: 2.8270\nepoch [156/500], d_loss: 0.3895 | g_loss: 2.8303\nepoch [157/500], d_loss: 0.4004 | g_loss: 2.8460\nepoch [158/500], d_loss: 0.3849 | g_loss: 2.8468\nepoch [159/500], d_loss: 0.3768 | g_loss: 2.8772\nepoch [160/500], d_loss: 0.4014 | g_loss: 2.8539\nepoch [161/500], d_loss: 0.3879 | g_loss: 2.8638\nepoch [162/500], d_loss: 0.3998 | g_loss: 2.8550\nepoch [163/500], d_loss: 0.3799 | g_loss: 2.8037\nepoch [164/500], d_loss: 0.3855 | g_loss: 2.8681\nepoch [165/500], d_loss: 0.3944 | g_loss: 2.8480\nepoch [166/500], d_loss: 0.3779 | g_loss: 2.8523\nepoch [167/500], d_loss: 0.3740 | g_loss: 2.8684\nepoch [168/500], d_loss: 0.4021 | g_loss: 2.8563\nepoch [169/500], d_loss: 0.3778 | g_loss: 2.9058\nepoch [170/500], d_loss: 0.4023 | g_loss: 2.8555\nepoch [171/500], d_loss: 0.4107 | g_loss: 2.8559\nepoch [172/500], d_loss: 0.3590 | g_loss: 2.8566\nepoch [173/500], d_loss: 0.4100 | g_loss: 2.8594\nepoch [174/500], d_loss: 0.4200 | g_loss: 2.8340\nepoch [175/500], d_loss: 0.3985 | g_loss: 2.8100\nepoch [176/500], d_loss: 0.3775 | g_loss: 2.8468\nepoch [177/500], d_loss: 0.3834 | g_loss: 2.8131\nepoch [178/500], d_loss: 0.3817 | g_loss: 2.8698\nepoch [179/500], d_loss: 0.3984 | g_loss: 2.8441\nepoch [180/500], d_loss: 0.3854 | g_loss: 2.8024\nepoch [181/500], d_loss: 0.3903 | g_loss: 2.8484\nepoch [182/500], d_loss: 0.4247 | g_loss: 2.8441\nepoch [183/500], d_loss: 0.3938 | g_loss: 2.8392\nepoch [184/500], d_loss: 0.3907 | g_loss: 2.8062\nepoch [185/500], d_loss: 0.4042 | g_loss: 2.8523\nepoch [186/500], d_loss: 0.3773 | g_loss: 2.8671\nepoch [187/500], d_loss: 0.4096 | g_loss: 2.8471\nepoch [188/500], d_loss: 0.4047 | g_loss: 2.8039\nepoch [189/500], d_loss: 0.4277 | g_loss: 2.8243\nepoch [190/500], d_loss: 0.3980 | g_loss: 2.8406\nepoch [191/500], d_loss: 0.4141 | g_loss: 2.8614\nepoch [192/500], d_loss: 0.4146 | g_loss: 2.8536\nepoch [193/500], d_loss: 0.3915 | g_loss: 2.8604\nepoch [194/500], d_loss: 0.4093 | g_loss: 2.8305\nepoch [195/500], d_loss: 0.3925 | g_loss: 2.8554\nepoch [196/500], d_loss: 0.4095 | g_loss: 2.8890\nepoch [197/500], d_loss: 0.3997 | g_loss: 2.8555\nepoch [198/500], d_loss: 0.3811 | g_loss: 2.8583\nepoch [199/500], d_loss: 0.4234 | g_loss: 2.8442\nepoch [200/500], d_loss: 0.3778 | g_loss: 2.8362\nepoch [201/500], d_loss: 0.3901 | g_loss: 2.8657\nepoch [202/500], d_loss: 0.3840 | g_loss: 2.8682\nepoch [203/500], d_loss: 0.4213 | g_loss: 2.8284\nepoch [204/500], d_loss: 0.3742 | g_loss: 2.8230\nepoch [205/500], d_loss: 0.3824 | g_loss: 2.8803\nepoch [206/500], d_loss: 0.4130 | g_loss: 2.8461\nepoch [207/500], d_loss: 0.3909 | g_loss: 2.8863\nepoch [208/500], d_loss: 0.3985 | g_loss: 2.8797\nepoch [209/500], d_loss: 0.3616 | g_loss: 2.8271\nepoch [210/500], d_loss: 0.4049 | g_loss: 2.8263\nepoch [211/500], d_loss: 0.3636 | g_loss: 2.8902\nepoch [212/500], d_loss: 0.3899 | g_loss: 2.8320\nepoch [213/500], d_loss: 0.4020 | g_loss: 2.8556\nepoch [214/500], d_loss: 0.4180 | g_loss: 2.8213\nepoch [215/500], d_loss: 0.4073 | g_loss: 2.8539\nepoch [216/500], d_loss: 0.4169 | g_loss: 2.8604\nepoch [217/500], d_loss: 0.4020 | g_loss: 2.8342\nepoch [218/500], d_loss: 0.3855 | g_loss: 2.8194\nepoch [219/500], d_loss: 0.3753 | g_loss: 2.8379\nepoch [220/500], d_loss: 0.4013 | g_loss: 2.8436\nepoch [221/500], d_loss: 0.4100 | g_loss: 2.8423\nepoch [222/500], d_loss: 0.3918 | g_loss: 2.8178\nepoch [223/500], d_loss: 0.4063 | g_loss: 2.8181\nepoch [224/500], d_loss: 0.4042 | g_loss: 2.8463\nepoch [225/500], d_loss: 0.4211 | g_loss: 2.8562\nepoch [226/500], d_loss: 0.3503 | g_loss: 2.8887\nepoch [227/500], d_loss: 0.3746 | g_loss: 2.8102\nepoch [228/500], d_loss: 0.4021 | g_loss: 2.8350\nepoch [229/500], d_loss: 0.4097 | g_loss: 2.8724\nepoch [230/500], d_loss: 0.3763 | g_loss: 2.8553\nepoch [231/500], d_loss: 0.4156 | g_loss: 2.8647\nepoch [232/500], d_loss: 0.4036 | g_loss: 2.8629\nepoch [233/500], d_loss: 0.3937 | g_loss: 2.8588\nepoch [234/500], d_loss: 0.3972 | g_loss: 2.8520\nepoch [235/500], d_loss: 0.3652 | g_loss: 2.8466\nepoch [236/500], d_loss: 0.4219 | g_loss: 2.8155\nepoch [237/500], d_loss: 0.3962 | g_loss: 2.8184\nepoch [238/500], d_loss: 0.4021 | g_loss: 2.8567\nepoch [239/500], d_loss: 0.3885 | g_loss: 2.8774\nepoch [240/500], d_loss: 0.3878 | g_loss: 2.8335\nepoch [241/500], d_loss: 0.4077 | g_loss: 2.8240\nepoch [242/500], d_loss: 0.3980 | g_loss: 2.8465\nepoch [243/500], d_loss: 0.3997 | g_loss: 2.8908\nepoch [244/500], d_loss: 0.4099 | g_loss: 2.8517\nepoch [245/500], d_loss: 0.3944 | g_loss: 2.8339\nepoch [246/500], d_loss: 0.4299 | g_loss: 2.8355\nepoch [247/500], d_loss: 0.4201 | g_loss: 2.8509\nepoch [248/500], d_loss: 0.4017 | g_loss: 2.8446\nepoch [249/500], d_loss: 0.4099 | g_loss: 2.8259\nepoch [250/500], d_loss: 0.4020 | g_loss: 2.8334\nepoch [251/500], d_loss: 0.3842 | g_loss: 2.8501\nepoch [252/500], d_loss: 0.3880 | g_loss: 2.8476\nepoch [253/500], d_loss: 0.3804 | g_loss: 2.8128\nepoch [254/500], d_loss: 0.4193 | g_loss: 2.9109\nepoch [255/500], d_loss: 0.4124 | g_loss: 2.7995\nepoch [256/500], d_loss: 0.4226 | g_loss: 2.8511\nepoch [257/500], d_loss: 0.4065 | g_loss: 2.8427\nepoch [258/500], d_loss: 0.4244 | g_loss: 2.8332\nepoch [259/500], d_loss: 0.4023 | g_loss: 2.8287\nepoch [260/500], d_loss: 0.3611 | g_loss: 2.8390\nepoch [261/500], d_loss: 0.4102 | g_loss: 2.8600\nepoch [262/500], d_loss: 0.3958 | g_loss: 2.8216\nepoch [263/500], d_loss: 0.3667 | g_loss: 2.8515\nepoch [264/500], d_loss: 0.4049 | g_loss: 2.8462\nepoch [265/500], d_loss: 0.3765 | g_loss: 2.8475\nepoch [266/500], d_loss: 0.4119 | g_loss: 2.8584\nepoch [267/500], d_loss: 0.3950 | g_loss: 2.8351\nepoch [268/500], d_loss: 0.4026 | g_loss: 2.8597\nepoch [269/500], d_loss: 0.3940 | g_loss: 2.8714\nepoch [270/500], d_loss: 0.4023 | g_loss: 2.8531\nepoch [271/500], d_loss: 0.4315 | g_loss: 2.8218\nepoch [272/500], d_loss: 0.4195 | g_loss: 2.8621\nepoch [273/500], d_loss: 0.3982 | g_loss: 2.8551\nepoch [274/500], d_loss: 0.4052 | g_loss: 2.8378\nepoch [275/500], d_loss: 0.4142 | g_loss: 2.8232\nepoch [276/500], d_loss: 0.3726 | g_loss: 2.8324\nepoch [277/500], d_loss: 0.3863 | g_loss: 2.8420\nepoch [278/500], d_loss: 0.4132 | g_loss: 2.8424\nepoch [279/500], d_loss: 0.3952 | g_loss: 2.8392\nepoch [280/500], d_loss: 0.4269 | g_loss: 2.8569\nepoch [281/500], d_loss: 0.3873 | g_loss: 2.8407\nepoch [282/500], d_loss: 0.4037 | g_loss: 2.8320\nepoch [283/500], d_loss: 0.4030 | g_loss: 2.8111\nepoch [284/500], d_loss: 0.4307 | g_loss: 2.8082\nepoch [285/500], d_loss: 0.4177 | g_loss: 2.7909\nepoch [286/500], d_loss: 0.4232 | g_loss: 2.8254\nepoch [287/500], d_loss: 0.4178 | g_loss: 2.8484\nepoch [288/500], d_loss: 0.3734 | g_loss: 2.8656\nepoch [289/500], d_loss: 0.3724 | g_loss: 2.8341\nepoch [290/500], d_loss: 0.4411 | g_loss: 2.8309\nepoch [291/500], d_loss: 0.4160 | g_loss: 2.8045\nepoch [292/500], d_loss: 0.4008 | g_loss: 2.8507\nepoch [293/500], d_loss: 0.3909 | g_loss: 2.8428\nepoch [294/500], d_loss: 0.3835 | g_loss: 2.8521\nepoch [295/500], d_loss: 0.3966 | g_loss: 2.8353\nepoch [296/500], d_loss: 0.4303 | g_loss: 2.8149\nepoch [297/500], d_loss: 0.3839 | g_loss: 2.8454\nepoch [298/500], d_loss: 0.3827 | g_loss: 2.8614\nepoch [299/500], d_loss: 0.4100 | g_loss: 2.8814\nepoch [300/500], d_loss: 0.4005 | g_loss: 2.8248\nepoch [301/500], d_loss: 0.3829 | g_loss: 2.8830\nepoch [302/500], d_loss: 0.4178 | g_loss: 2.8528\nepoch [303/500], d_loss: 0.4002 | g_loss: 2.8373\nepoch [304/500], d_loss: 0.4243 | g_loss: 2.8532\nepoch [305/500], d_loss: 0.3963 | g_loss: 2.8375\nepoch [306/500], d_loss: 0.3970 | g_loss: 2.8219\nepoch [307/500], d_loss: 0.4196 | g_loss: 2.8125\nepoch [308/500], d_loss: 0.3887 | g_loss: 2.8600\nepoch [309/500], d_loss: 0.4171 | g_loss: 2.8592\nepoch [310/500], d_loss: 0.4068 | g_loss: 2.8279\nepoch [311/500], d_loss: 0.3952 | g_loss: 2.8559\nepoch [312/500], d_loss: 0.3819 | g_loss: 2.7990\nepoch [313/500], d_loss: 0.4070 | g_loss: 2.8212\nepoch [314/500], d_loss: 0.3911 | g_loss: 2.8333\nepoch [315/500], d_loss: 0.4430 | g_loss: 2.8394\nepoch [316/500], d_loss: 0.3837 | g_loss: 2.8334\nepoch [317/500], d_loss: 0.4195 | g_loss: 2.8576\nepoch [318/500], d_loss: 0.3767 | g_loss: 2.8652\nepoch [319/500], d_loss: 0.3936 | g_loss: 2.8260\nepoch [320/500], d_loss: 0.3902 | g_loss: 2.8784\nepoch [321/500], d_loss: 0.4248 | g_loss: 2.8511\nepoch [322/500], d_loss: 0.3883 | g_loss: 2.8547\nepoch [323/500], d_loss: 0.4090 | g_loss: 2.8306\nepoch [324/500], d_loss: 0.4162 | g_loss: 2.8496\nepoch [325/500], d_loss: 0.3609 | g_loss: 2.8860\nepoch [326/500], d_loss: 0.3962 | g_loss: 2.8412\nepoch [327/500], d_loss: 0.3874 | g_loss: 2.8658\nepoch [328/500], d_loss: 0.4093 | g_loss: 2.8198\nepoch [329/500], d_loss: 0.3606 | g_loss: 2.8707\nepoch [330/500], d_loss: 0.3551 | g_loss: 2.8558\nepoch [331/500], d_loss: 0.3688 | g_loss: 2.8555\nepoch [332/500], d_loss: 0.3978 | g_loss: 2.8404\nepoch [333/500], d_loss: 0.3962 | g_loss: 2.8309\nepoch [334/500], d_loss: 0.3879 | g_loss: 2.8399\nepoch [335/500], d_loss: 0.3639 | g_loss: 2.8459\nepoch [336/500], d_loss: 0.4109 | g_loss: 2.8607\nepoch [337/500], d_loss: 0.3685 | g_loss: 2.8315\nepoch [338/500], d_loss: 0.4253 | g_loss: 2.8188\nepoch [339/500], d_loss: 0.4224 | g_loss: 2.8500\nepoch [340/500], d_loss: 0.3748 | g_loss: 2.8485\nepoch [341/500], d_loss: 0.4122 | g_loss: 2.8418\nepoch [342/500], d_loss: 0.4246 | g_loss: 2.8881\nepoch [343/500], d_loss: 0.3916 | g_loss: 2.8404\nepoch [344/500], d_loss: 0.4095 | g_loss: 2.8280\nepoch [345/500], d_loss: 0.3777 | g_loss: 2.8493\nepoch [346/500], d_loss: 0.3928 | g_loss: 2.8569\nepoch [347/500], d_loss: 0.3621 | g_loss: 2.8293\nepoch [348/500], d_loss: 0.4191 | g_loss: 2.8345\nepoch [349/500], d_loss: 0.4069 | g_loss: 2.8358\nepoch [350/500], d_loss: 0.3884 | g_loss: 2.8602\nepoch [351/500], d_loss: 0.4124 | g_loss: 2.8381\nepoch [352/500], d_loss: 0.3948 | g_loss: 2.8555\nepoch [353/500], d_loss: 0.3940 | g_loss: 2.8480\nepoch [354/500], d_loss: 0.4066 | g_loss: 2.8533\nepoch [355/500], d_loss: 0.3934 | g_loss: 2.8342\nepoch [356/500], d_loss: 0.4004 | g_loss: 2.8626\nepoch [357/500], d_loss: 0.4225 | g_loss: 2.8263\nepoch [358/500], d_loss: 0.3745 | g_loss: 2.8306\nepoch [359/500], d_loss: 0.4031 | g_loss: 2.8915\nepoch [360/500], d_loss: 0.3903 | g_loss: 2.8192\nepoch [361/500], d_loss: 0.4256 | g_loss: 2.7936\nepoch [362/500], d_loss: 0.3952 | g_loss: 2.8561\nepoch [363/500], d_loss: 0.3987 | g_loss: 2.8551\nepoch [364/500], d_loss: 0.3724 | g_loss: 2.8818\nepoch [365/500], d_loss: 0.3703 | g_loss: 2.8420\nepoch [366/500], d_loss: 0.4046 | g_loss: 2.8760\nepoch [367/500], d_loss: 0.3904 | g_loss: 2.8818\nepoch [368/500], d_loss: 0.3735 | g_loss: 2.8516\nepoch [369/500], d_loss: 0.3708 | g_loss: 2.8876\nepoch [370/500], d_loss: 0.3879 | g_loss: 2.8479\nepoch [371/500], d_loss: 0.3875 | g_loss: 2.8164\nepoch [372/500], d_loss: 0.4128 | g_loss: 2.8234\nepoch [373/500], d_loss: 0.4091 | g_loss: 2.8284\nepoch [374/500], d_loss: 0.4198 | g_loss: 2.8699\nepoch [375/500], d_loss: 0.4236 | g_loss: 2.8310\nepoch [376/500], d_loss: 0.3934 | g_loss: 2.8611\nepoch [377/500], d_loss: 0.4043 | g_loss: 2.8405\nepoch [378/500], d_loss: 0.3961 | g_loss: 2.8581\nepoch [379/500], d_loss: 0.4127 | g_loss: 2.7893\nepoch [380/500], d_loss: 0.4127 | g_loss: 2.8521\nepoch [381/500], d_loss: 0.3962 | g_loss: 2.8530\nepoch [382/500], d_loss: 0.4110 | g_loss: 2.8358\nepoch [383/500], d_loss: 0.3867 | g_loss: 2.8545\nepoch [384/500], d_loss: 0.3827 | g_loss: 2.8724\nepoch [385/500], d_loss: 0.4114 | g_loss: 2.8572\nepoch [386/500], d_loss: 0.3866 | g_loss: 2.8397\nepoch [387/500], d_loss: 0.3985 | g_loss: 2.8592\nepoch [388/500], d_loss: 0.3680 | g_loss: 2.8183\nepoch [389/500], d_loss: 0.3987 | g_loss: 2.8090\nepoch [390/500], d_loss: 0.4186 | g_loss: 2.8174\nepoch [391/500], d_loss: 0.4128 | g_loss: 2.8177\nepoch [392/500], d_loss: 0.3896 | g_loss: 2.8561\nepoch [393/500], d_loss: 0.3932 | g_loss: 2.8083\nepoch [394/500], d_loss: 0.3770 | g_loss: 2.8720\nepoch [395/500], d_loss: 0.3816 | g_loss: 2.8672\nepoch [396/500], d_loss: 0.4002 | g_loss: 2.8381\nepoch [397/500], d_loss: 0.3772 | g_loss: 2.8771\nepoch [398/500], d_loss: 0.4052 | g_loss: 2.8237\nepoch [399/500], d_loss: 0.4022 | g_loss: 2.8324\nepoch [400/500], d_loss: 0.4056 | g_loss: 2.8530\nepoch [401/500], d_loss: 0.3874 | g_loss: 2.8442\nepoch [402/500], d_loss: 0.4005 | g_loss: 2.8443\nepoch [403/500], d_loss: 0.3962 | g_loss: 2.8507\nepoch [404/500], d_loss: 0.3728 | g_loss: 2.8453\nepoch [405/500], d_loss: 0.4316 | g_loss: 2.8554\nepoch [406/500], d_loss: 0.3968 | g_loss: 2.8306\nepoch [407/500], d_loss: 0.3847 | g_loss: 2.8663\nepoch [408/500], d_loss: 0.3756 | g_loss: 2.8620\nepoch [409/500], d_loss: 0.3811 | g_loss: 2.8609\nepoch [410/500], d_loss: 0.3900 | g_loss: 2.8444\nepoch [411/500], d_loss: 0.4174 | g_loss: 2.8412\nepoch [412/500], d_loss: 0.4181 | g_loss: 2.8327\nepoch [413/500], d_loss: 0.3909 | g_loss: 2.8198\nepoch [414/500], d_loss: 0.4000 | g_loss: 2.8543\nepoch [415/500], d_loss: 0.3982 | g_loss: 2.8305\nepoch [416/500], d_loss: 0.4130 | g_loss: 2.8534\nepoch [417/500], d_loss: 0.4308 | g_loss: 2.8424\nepoch [418/500], d_loss: 0.3968 | g_loss: 2.8259\nepoch [419/500], d_loss: 0.4072 | g_loss: 2.8857\nepoch [420/500], d_loss: 0.3797 | g_loss: 2.8461\nepoch [421/500], d_loss: 0.3991 | g_loss: 2.8575\nepoch [422/500], d_loss: 0.4135 | g_loss: 2.8478\nepoch [423/500], d_loss: 0.3816 | g_loss: 2.8345\nepoch [424/500], d_loss: 0.4196 | g_loss: 2.8299\nepoch [425/500], d_loss: 0.4163 | g_loss: 2.8498\nepoch [426/500], d_loss: 0.3824 | g_loss: 2.8603\nepoch [427/500], d_loss: 0.3880 | g_loss: 2.8290\nepoch [428/500], d_loss: 0.4019 | g_loss: 2.8474\nepoch [429/500], d_loss: 0.3922 | g_loss: 2.8405\nepoch [430/500], d_loss: 0.4204 | g_loss: 2.8488\nepoch [431/500], d_loss: 0.3724 | g_loss: 2.8642\nepoch [432/500], d_loss: 0.3891 | g_loss: 2.8748\nepoch [433/500], d_loss: 0.3930 | g_loss: 2.8467\nepoch [434/500], d_loss: 0.3877 | g_loss: 2.8698\nepoch [435/500], d_loss: 0.4198 | g_loss: 2.8656\nepoch [436/500], d_loss: 0.3925 | g_loss: 2.8289\nepoch [437/500], d_loss: 0.4273 | g_loss: 2.8410\nepoch [438/500], d_loss: 0.3840 | g_loss: 2.8134\nepoch [439/500], d_loss: 0.3843 | g_loss: 2.8089\nepoch [440/500], d_loss: 0.4175 | g_loss: 2.8493\nepoch [441/500], d_loss: 0.4030 | g_loss: 2.8398\nepoch [442/500], d_loss: 0.4129 | g_loss: 2.8521\nepoch [443/500], d_loss: 0.4386 | g_loss: 2.8503\nepoch [444/500], d_loss: 0.3946 | g_loss: 2.8772\nepoch [445/500], d_loss: 0.3897 | g_loss: 2.8578\nepoch [446/500], d_loss: 0.3713 | g_loss: 2.8444\nepoch [447/500], d_loss: 0.4078 | g_loss: 2.8252\nepoch [448/500], d_loss: 0.4178 | g_loss: 2.8481\nepoch [449/500], d_loss: 0.3993 | g_loss: 2.8645\nepoch [450/500], d_loss: 0.4086 | g_loss: 2.8627\nepoch [451/500], d_loss: 0.4158 | g_loss: 2.8460\nepoch [452/500], d_loss: 0.3814 | g_loss: 2.8598\nepoch [453/500], d_loss: 0.4069 | g_loss: 2.8304\nepoch [454/500], d_loss: 0.4058 | g_loss: 2.8551\nepoch [455/500], d_loss: 0.4260 | g_loss: 2.8501\nepoch [456/500], d_loss: 0.4217 | g_loss: 2.8827\nepoch [457/500], d_loss: 0.4381 | g_loss: 2.8233\nepoch [458/500], d_loss: 0.3793 | g_loss: 2.8696\nepoch [459/500], d_loss: 0.3996 | g_loss: 2.8558\nepoch [460/500], d_loss: 0.4173 | g_loss: 2.8458\nepoch [461/500], d_loss: 0.3876 | g_loss: 2.8527\nepoch [462/500], d_loss: 0.4099 | g_loss: 2.8466\nepoch [463/500], d_loss: 0.3673 | g_loss: 2.8311\nepoch [464/500], d_loss: 0.4075 | g_loss: 2.8566\nepoch [465/500], d_loss: 0.4043 | g_loss: 2.8561\nepoch [466/500], d_loss: 0.4214 | g_loss: 2.7970\nepoch [467/500], d_loss: 0.3805 | g_loss: 2.8303\nepoch [468/500], d_loss: 0.3939 | g_loss: 2.8543\nepoch [469/500], d_loss: 0.4418 | g_loss: 2.8426\nepoch [470/500], d_loss: 0.4064 | g_loss: 2.8494\nepoch [471/500], d_loss: 0.3962 | g_loss: 2.8396\nepoch [472/500], d_loss: 0.3697 | g_loss: 2.8625\nepoch [473/500], d_loss: 0.3989 | g_loss: 2.8632\nepoch [474/500], d_loss: 0.4125 | g_loss: 2.8718\nepoch [475/500], d_loss: 0.4102 | g_loss: 2.8462\nepoch [476/500], d_loss: 0.4201 | g_loss: 2.8286\nepoch [477/500], d_loss: 0.4034 | g_loss: 2.8428\nepoch [478/500], d_loss: 0.4080 | g_loss: 2.8360\nepoch [479/500], d_loss: 0.4319 | g_loss: 2.8647\nepoch [480/500], d_loss: 0.4216 | g_loss: 2.8544\nepoch [481/500], d_loss: 0.4020 | g_loss: 2.8635\nepoch [482/500], d_loss: 0.4295 | g_loss: 2.8481\nepoch [483/500], d_loss: 0.4269 | g_loss: 2.8661\nepoch [484/500], d_loss: 0.3763 | g_loss: 2.8618\nepoch [485/500], d_loss: 0.4048 | g_loss: 2.8539\nepoch [486/500], d_loss: 0.3942 | g_loss: 2.8327\nepoch [487/500], d_loss: 0.4157 | g_loss: 2.8315\nepoch [488/500], d_loss: 0.3772 | g_loss: 2.8205\nepoch [489/500], d_loss: 0.3886 | g_loss: 2.8289\nepoch [490/500], d_loss: 0.4177 | g_loss: 2.8250\nepoch [491/500], d_loss: 0.3892 | g_loss: 2.8605\nepoch [492/500], d_loss: 0.3848 | g_loss: 2.8307\nepoch [493/500], d_loss: 0.3871 | g_loss: 2.8733\nepoch [494/500], d_loss: 0.3859 | g_loss: 2.8281\nepoch [495/500], d_loss: 0.3860 | g_loss: 2.8420\nepoch [496/500], d_loss: 0.4039 | g_loss: 2.8417\nepoch [497/500], d_loss: 0.3971 | g_loss: 2.8534\nepoch [498/500], d_loss: 0.4018 | g_loss: 2.8642\nepoch [499/500], d_loss: 0.3890 | g_loss: 2.8677\nepoch [500/500], d_loss: 0.4078 | g_loss: 2.8642\n","output_type":"stream"}]},{"cell_type":"code","source":"# Here I am generating new data\nG.eval()\nunique_labels = np.unique(y_train)\ndict_len = {}\nmax_len = 0\n\nfor label in unique_labels:\n    dict_len[label] = len(np.where(y_train == label)[0])\n    if max_len < dict_len[label]:\n        max_len = dict_len[label]\n        \nnew_data = {}\n\nfor label in unique_labels:\n    if max_len > dict_len[label]:\n        size = max_len - dict_len[label]\n        y = torch.ones((size), dtype = torch.int64).to(device) * label\n        z = np.random.uniform(-1, 1, size = (size, z_size))\n        z = torch.from_numpy(z).float().to(device)\n        new_data[label] = G(z, y).cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:23:26.637352Z","iopub.execute_input":"2022-05-18T04:23:26.637924Z","iopub.status.idle":"2022-05-18T04:23:26.912948Z","shell.execute_reply.started":"2022-05-18T04:23:26.637886Z","shell.execute_reply":"2022-05-18T04:23:26.912100Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"# Here is newly generated data\nnew_data","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:23:28.641048Z","iopub.execute_input":"2022-05-18T04:23:28.641334Z","iopub.status.idle":"2022-05-18T04:23:28.654993Z","shell.execute_reply.started":"2022-05-18T04:23:28.641303Z","shell.execute_reply":"2022-05-18T04:23:28.654339Z"},"trusted":true},"execution_count":232,"outputs":[{"execution_count":232,"output_type":"execute_result","data":{"text/plain":"{0: array([[ 0.82648975,  0.6938739 , -0.16330588, ..., -0.80351794,\n         -0.730387  ,  0.95089126],\n        [ 0.82003474,  0.70670223, -0.11075535, ..., -0.7480745 ,\n         -0.7210134 ,  0.93861014],\n        [ 0.6846276 ,  0.5665753 , -0.05828349, ..., -0.68005884,\n         -0.6099124 ,  0.8518565 ],\n        ...,\n        [ 0.8363304 ,  0.730654  , -0.16781649, ..., -0.78669643,\n         -0.7281877 ,  0.95153016],\n        [ 0.5514046 ,  0.44331607, -0.02253831, ..., -0.62286586,\n         -0.53327906,  0.7581653 ],\n        [ 0.50857645,  0.4207632 , -0.0356461 , ..., -0.6079501 ,\n         -0.5270349 ,  0.7426068 ]], dtype=float32),\n 1: array([[ 0.04596491,  0.44414625, -0.17368749, ..., -0.73869634,\n         -0.08327262,  0.22489479],\n        [ 0.19919805,  0.4912507 , -0.12367153, ..., -0.68481183,\n         -0.22036065,  0.37008792],\n        [ 0.01410807,  0.41560337, -0.11950813, ..., -0.674502  ,\n         -0.08875272,  0.12634438],\n        ...,\n        [ 0.11690559,  0.4430459 , -0.11973233, ..., -0.6978413 ,\n         -0.1424714 ,  0.32285187],\n        [ 0.23403567,  0.5164437 , -0.1952347 , ..., -0.7759789 ,\n         -0.16046117,  0.42170238],\n        [ 0.00498759,  0.40035695, -0.13864219, ..., -0.6699554 ,\n         -0.08608776,  0.14408396]], dtype=float32),\n 2: array([[ 0.4406577 ,  0.5671621 , -0.10277682, ..., -0.678125  ,\n         -0.38398814,  0.6882072 ],\n        [ 0.5602325 ,  0.6480831 , -0.15828161, ..., -0.7422596 ,\n         -0.4579322 ,  0.8010701 ],\n        [ 0.17870718,  0.39599213, -0.01676879, ..., -0.5414934 ,\n         -0.23515026,  0.38784957],\n        ...,\n        [ 0.13465476,  0.4030897 , -0.04973411, ..., -0.5584578 ,\n         -0.21059738,  0.34089476],\n        [ 0.49702814,  0.6357964 , -0.12976612, ..., -0.70791936,\n         -0.40713912,  0.7394903 ],\n        [ 0.63606834,  0.71919537, -0.18553914, ..., -0.7898173 ,\n         -0.496262  ,  0.8533524 ]], dtype=float32),\n 3: array([[ 0.9451435 ,  0.8600081 , -0.30177075, ..., -0.9102888 ,\n         -0.84483415,  0.99375695],\n        [ 0.93967414,  0.83801013, -0.3049277 , ..., -0.9118561 ,\n         -0.8489677 ,  0.99317473],\n        [ 0.914864  ,  0.7904642 , -0.26320308, ..., -0.90356666,\n         -0.8156371 ,  0.9880438 ],\n        ...,\n        [ 0.9452166 ,  0.8511175 , -0.30636975, ..., -0.91877764,\n         -0.84860575,  0.9934635 ],\n        [ 0.90115094,  0.78174865, -0.24598348, ..., -0.87812394,\n         -0.8057687 ,  0.9837982 ],\n        [ 0.9489536 ,  0.8626151 , -0.31548434, ..., -0.91580707,\n         -0.85862017,  0.99413395]], dtype=float32),\n 4: array([[ 0.07573786,  0.48706147, -0.31105825, ..., -0.88180315,\n          0.00621183,  0.34410927],\n        [ 0.12344361,  0.57331455, -0.41062412, ..., -0.9292963 ,\n          0.06084974,  0.43004623],\n        [-0.09502054,  0.41604277, -0.2741957 , ..., -0.8540608 ,\n          0.08752505,  0.12882929],\n        ...,\n        [ 0.04913159,  0.5021353 , -0.34126776, ..., -0.9113139 ,\n          0.06319249,  0.35096705],\n        [ 0.03139431,  0.50154305, -0.33549026, ..., -0.89264214,\n          0.03319936,  0.31591973],\n        [-0.16342664,  0.41140565, -0.28325522, ..., -0.872982  ,\n          0.15904567,  0.04180957]], dtype=float32),\n 5: array([[ 0.8438248 ,  0.87846124,  0.22818953, ..., -0.24815989,\n         -0.79217684,  0.8253222 ],\n        [ 0.41937408,  0.5783156 ,  0.22151488, ..., -0.1703054 ,\n         -0.5025511 ,  0.375002  ],\n        [ 0.4988256 ,  0.652111  ,  0.23667794, ..., -0.13157625,\n         -0.5665091 ,  0.41594586],\n        ...,\n        [ 0.69349444,  0.78102815,  0.22142261, ..., -0.20913957,\n         -0.6833759 ,  0.62929356],\n        [ 0.74254596,  0.8083003 ,  0.21719582, ..., -0.2442007 ,\n         -0.71403086,  0.71403766],\n        [ 0.6365833 ,  0.7315986 ,  0.24807332, ..., -0.16566262,\n         -0.6609795 ,  0.5937401 ]], dtype=float32),\n 7: array([[ 3.70991439e-01,  7.06088841e-01, -1.29417464e-01, ...,\n         -7.09638476e-01, -3.02420646e-01,  5.14813423e-01],\n        [ 1.05995595e-01,  5.37808299e-01, -9.15490687e-02, ...,\n         -6.34613276e-01, -1.69628575e-01,  1.96941689e-01],\n        [-3.24159861e-04,  5.08471072e-01, -7.90395066e-02, ...,\n         -6.23605072e-01, -8.47486705e-02,  3.00991647e-02],\n        ...,\n        [ 3.77002060e-01,  6.84071839e-01, -1.59334704e-01, ...,\n         -7.56372452e-01, -3.24784428e-01,  5.81746638e-01],\n        [-1.42963771e-02,  4.99631703e-01, -1.55243399e-02, ...,\n         -5.35507798e-01, -1.45070210e-01, -1.48543818e-02],\n        [ 1.25197251e-03,  5.66112399e-01, -8.91535133e-02, ...,\n         -6.03614450e-01, -7.53376707e-02, -2.09873933e-02]], dtype=float32),\n 8: array([[ 0.15977561,  0.34089237,  0.04809475, ..., -0.41876078,\n         -0.2586996 ,  0.22298801],\n        [ 0.15392934,  0.3188404 ,  0.05721912, ..., -0.39251146,\n         -0.24091932,  0.21624279],\n        [ 0.27848276,  0.43410647,  0.070398  , ..., -0.38660458,\n         -0.3206784 ,  0.3084299 ],\n        ...,\n        [ 0.23319769,  0.36528406,  0.07173563, ..., -0.39520043,\n         -0.30165792,  0.30765837],\n        [ 0.3512272 ,  0.5101872 ,  0.00912725, ..., -0.47352266,\n         -0.33539772,  0.43097505],\n        [ 0.34074092,  0.492132  ,  0.02276395, ..., -0.4547821 ,\n         -0.34658358,  0.41343585]], dtype=float32),\n 9: array([[ 0.06988595,  0.1975772 ,  0.01368339, ..., -0.46361318,\n         -0.21448305,  0.18134011],\n        [ 0.03147001,  0.12415966,  0.02653159, ..., -0.4327374 ,\n         -0.21157528,  0.125077  ],\n        [ 0.17978792,  0.2467486 , -0.02606577, ..., -0.5515533 ,\n         -0.30361056,  0.38853493],\n        ...,\n        [ 0.13273439,  0.24744457, -0.04578115, ..., -0.5618391 ,\n         -0.2540827 ,  0.31888732],\n        [ 0.08861536,  0.20722798, -0.02612912, ..., -0.5157272 ,\n         -0.23624524,  0.23398574],\n        [ 0.05703755,  0.16328461, -0.00410946, ..., -0.47649652,\n         -0.21097726,  0.17486276]], dtype=float32)}"},"metadata":{}}]},{"cell_type":"code","source":"# Here I am creating the new train test data using the previous and generated data\nlabels = []\ninputs = []\n\nfor key, value in new_data.items():\n    size = len(value)\n    labels.append(np.ones(size) * key)\n    inputs.append(value)\n        \n    labels.append(y_train.numpy())\n    inputs.append(x_train.numpy())\n\n    new_x = np.concatenate(inputs)\n    new_y = np.concatenate(labels)\n\n    s_index = np.random.permutation(len(new_x))\n    \n    new_x = new_x[s_index]\n    new_y = new_y[s_index]\n    \n    new_x_train = torch.tensor(new_x)\n    new_y_train = torch.tensor(new_y, dtype=torch.int64)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:24:41.084558Z","iopub.execute_input":"2022-05-18T04:24:41.084804Z","iopub.status.idle":"2022-05-18T04:24:45.294905Z","shell.execute_reply.started":"2022-05-18T04:24:41.084777Z","shell.execute_reply":"2022-05-18T04:24:45.293894Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"# Here is the new data\nnew_x","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:24:45.297532Z","iopub.execute_input":"2022-05-18T04:24:45.297923Z","iopub.status.idle":"2022-05-18T04:24:45.307843Z","shell.execute_reply.started":"2022-05-18T04:24:45.297875Z","shell.execute_reply":"2022-05-18T04:24:45.306501Z"},"trusted":true},"execution_count":234,"outputs":[{"execution_count":234,"output_type":"execute_result","data":{"text/plain":"array([[-1.4219648 , -0.20961441,  0.4202353 , ..., -0.11485821,\n        -0.753074  , -1.459825  ],\n       [ 0.10424016,  0.5557494 , -0.09838868, ..., -0.6291045 ,\n        -0.16270211,  0.19772401],\n       [ 0.11788639,  0.5436281 , -0.08746612, ..., -0.61640584,\n        -0.16525245,  0.23543686],\n       ...,\n       [ 1.5349711 , -0.20977429,  0.4202353 , ...,  1.2070237 ,\n         0.7343404 ,  0.6850136 ],\n       [ 0.08633551,  0.1724255 ,  0.01022314, ..., -0.45862252,\n        -0.24492627,  0.21430612],\n       [-0.05731323, -0.16397668,  0.1518094 , ..., -0.35520038,\n         0.2695234 , -1.459825  ]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# Here I am testing the Random Forest with the initial data\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n\nclf = RandomForestClassifier(max_depth=100, random_state=0)\nclf.fit(x_train.numpy(), y_train.numpy())\nprint(classification_report(y_test, clf.predict(x_test)))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:24:47.492363Z","iopub.execute_input":"2022-05-18T04:24:47.492732Z","iopub.status.idle":"2022-05-18T04:25:23.512378Z","shell.execute_reply.started":"2022-05-18T04:24:47.492688Z","shell.execute_reply":"2022-05-18T04:25:23.511400Z"},"trusted":true},"execution_count":235,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.00      0.01      0.01       677\n           1       0.02      0.09      0.03       583\n           2       0.24      0.12      0.16      4089\n           3       0.80      0.59      0.68     11132\n           4       0.81      0.67      0.73      6062\n           5       1.00      0.96      0.98     18871\n           6       0.90      1.00      0.95     37000\n           7       0.96      0.74      0.84      3496\n           8       0.34      0.41      0.37       378\n           9       0.62      0.11      0.19        44\n\n    accuracy                           0.84     82332\n   macro avg       0.57      0.47      0.49     82332\nweighted avg       0.85      0.84      0.84     82332\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Here I am testing the RF with the newly generated data\nclf.fit(new_x, new_y)\nprint(classification_report(y_test, clf.predict(x_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:25:23.514069Z","iopub.execute_input":"2022-05-18T04:25:23.514336Z","iopub.status.idle":"2022-05-18T04:42:42.876104Z","shell.execute_reply.started":"2022-05-18T04:25:23.514300Z","shell.execute_reply":"2022-05-18T04:42:42.875303Z"},"trusted":true},"execution_count":236,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.02      0.03      0.03       677\n           1       0.02      0.08      0.03       583\n           2       0.24      0.10      0.14      4089\n           3       0.82      0.50      0.62     11132\n           4       0.71      0.56      0.63      6062\n           5       1.00      0.96      0.98     18871\n           6       0.84      1.00      0.91     37000\n           7       0.96      0.62      0.76      3496\n           8       0.28      0.30      0.29       378\n           9       0.57      0.09      0.16        44\n\n    accuracy                           0.81     82332\n   macro avg       0.55      0.43      0.45     82332\nweighted avg       0.82      0.81      0.81     82332\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install interpret","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:44:40.871452Z","iopub.execute_input":"2022-05-18T04:44:40.871738Z","iopub.status.idle":"2022-05-18T04:44:50.612458Z","shell.execute_reply.started":"2022-05-18T04:44:40.871709Z","shell.execute_reply":"2022-05-18T04:44:50.611070Z"},"trusted":true},"execution_count":239,"outputs":[{"name":"stdout","text":"Requirement already satisfied: interpret in /opt/conda/lib/python3.7/site-packages (0.2.7)\nRequirement already satisfied: interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7 in /opt/conda/lib/python3.7/site-packages (from interpret) (0.2.7)\nRequirement already satisfied: treeinterpreter>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.2.3)\nRequirement already satisfied: plotly>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (5.6.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.1.0)\nRequirement already satisfied: scikit-learn>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.0.1)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.7.3)\nRequirement already satisfied: pandas>=0.19.2 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.3.5)\nRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.20.3)\nRequirement already satisfied: lime>=0.1.1.33 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.2.0.1)\nRequirement already satisfied: dash-table>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (5.0.0)\nRequirement already satisfied: dash>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.4.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.26.0)\nRequirement already satisfied: gevent>=1.3.6 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (21.12.0)\nRequirement already satisfied: dash-cytoscape>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.3.0)\nRequirement already satisfied: ipykernel>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (6.6.0)\nRequirement already satisfied: ipython>=7.4.0 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (7.30.1)\nRequirement already satisfied: psutil>=5.6.2 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (5.9.0)\nRequirement already satisfied: dill>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.3.4)\nRequirement already satisfied: shap>=0.28.5 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.40.0)\nRequirement already satisfied: SALib>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.4.5)\nRequirement already satisfied: skope-rules>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.0.1)\nRequirement already satisfied: dash-html-components==2.0.0 in /opt/conda/lib/python3.7/site-packages (from dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.0.0)\nRequirement already satisfied: flask-compress in /opt/conda/lib/python3.7/site-packages (from dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.12)\nRequirement already satisfied: Flask>=1.0.4 in /opt/conda/lib/python3.7/site-packages (from dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.0.3)\nRequirement already satisfied: dash-core-components==2.0.0 in /opt/conda/lib/python3.7/site-packages (from dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (59.5.0)\nRequirement already satisfied: zope.event in /opt/conda/lib/python3.7/site-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (4.5.0)\nRequirement already satisfied: greenlet<2.0,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.1.2)\nRequirement already satisfied: zope.interface in /opt/conda/lib/python3.7/site-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (5.4.0)\nRequirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.5.1)\nRequirement already satisfied: traitlets<6.0,>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (5.1.1)\nRequirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (6.1)\nRequirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.1.3)\nRequirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (7.1.0)\nRequirement already satisfied: importlib-metadata<5 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (4.11.3)\nRequirement already satisfied: argcomplete>=1.12.3 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.12.3)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.10.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (3.0.24)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (5.1.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.18.1)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (4.8.0)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.7.5)\nRequirement already satisfied: scikit-image>=0.12 in /opt/conda/lib/python3.7/site-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.19.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (4.62.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (3.5.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.19.2->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.19.2->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2021.3)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=3.8.1->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (8.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from plotly>=3.8.1->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.16.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.26.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (3.1)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from SALib>=1.3.3->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.37.0)\nRequirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from SALib>=1.3.3->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.2.8)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.18.1->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (3.0.0)\nRequirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.7/site-packages (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (21.3)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.0.7)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.0.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.54.1)\nRequirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (8.0.3)\nRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.1.1)\nRequirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.0.2)\nRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (3.0.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (3.6.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (4.1.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.8.3)\nRequirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (22.3.0)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.3)\nRequirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.5.4)\nRequirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=5.1.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (4.9.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>20.9->shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (3.0.6)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.4.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.2.5)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.2.0)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (8.2.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2021.11.2)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.6.3)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.9.0)\nRequirement already satisfied: brotli in /opt/conda/lib/python3.7/site-packages (from flask-compress->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.0.9)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.3.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (4.28.4)\nRequirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.37.0)\nRequirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from pathos->SALib>=1.3.3->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.3.0)\nRequirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.7/site-packages (from pathos->SALib>=1.3.3->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (1.6.6.4)\nRequirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.7/site-packages (from pathos->SALib>=1.3.3->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (0.70.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=3.0->Flask>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.7->interpret) (2.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"from interpret.glassbox import ExplainableBoostingClassifier\nclf = ExplainableBoostingClassifier(max_bins=3, n_jobs=-1, interactions=0, max_leaves=25)\nclf.fit(x_train.numpy(),y_train.numpy())\nprint(classification_report(y_test, clf.predict(x_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T05:34:53.638108Z","iopub.status.idle":"2022-05-18T05:34:53.639637Z","shell.execute_reply.started":"2022-05-18T05:34:53.639340Z","shell.execute_reply":"2022-05-18T05:34:53.639371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(new_x, new_y)\nprint(classification_report(y_test, clf.predict(x_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T04:42:42.906048Z","iopub.status.idle":"2022-05-18T04:42:42.906847Z","shell.execute_reply.started":"2022-05-18T04:42:42.906535Z","shell.execute_reply":"2022-05-18T04:42:42.906569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class nnet(nn.Module):\n    \n  def __init__(self):\n    super(nnet, self).__init__()\n    self.model = nn.Sequential(\n      nn.Linear(41, 30),\n      nn.ReLU(True),\n      nn.Linear(30, 10)\n    )\n    self.model.apply(self.__init_weights)\n\n  def forward(self, x):\n    return self.model(x)\n  \n  def __init_weights(self,m):\n    if type(m) == nn.Linear:\n      torch.nn.init.xavier_uniform_(m.weight)\n      m.bias.data.fill_(0.01)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = nnet().to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=5e-4)\ncriterion = nn.CrossEntropyLoss()\n\nmodel.train()\n\nfor epoch in range(10):\n    for X, y in new_x, new_y:\n        X = X.to(device)\n        y = y.to(device)\n\n        optimizer.zero_grad()\n        output = model(X)\n        loss = criterion(output, y)\n\n        loss.backward()\n        optimizer.step()\nmodel.eval()\n\ny_pred = torch.max(model(x_test.to(device)).data, 1)[1].cpu().detach().numpy()\nprint(classification_report(y_pred, y_test.numpy()))","metadata":{},"execution_count":null,"outputs":[]}]}